{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "intensive-butter",
      "metadata": {
        "id": "intensive-butter"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "# model = torch.hub.load('pytorch/vision:v0.10.0', 'fcn_resnet50', pretrained=True, )\n",
        "\n",
        "from generate_training_validation_data import CustomImageDataset\n",
        "from Custom_small_FCN import FCN4s\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from PIL import Image\n",
        "import cv2 as cv\n",
        "\n",
        "from collections import namedtuple\n",
        "from typing import Any\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "\n",
        "train_data_dir = 'D:/MemeMachine_ProjectData/dataset/training'\n",
        "validation_data_dir = 'D:/MemeMachine_ProjectData/dataset/validation'\n",
        "img_width, img_height, n_channels = 1020, 1020, 3 #TODO change dimensions to be wider, to better support text\n",
        "\n",
        "epochs = 1 #50 TODO\n",
        "batch_size = 1\n",
        "classes = ['nothing', 'text']\n",
        "\n",
        "model = FCN4s(n_class=len(classes))\n",
        "\n",
        "# classes = ['text']\n",
        "\n",
        "\n",
        "#change the number of classes in the final step of the classifier\n",
        "# print(model.classifier[4])\n",
        "# model.classifier[4] = torch.nn.Conv2d(512, len(classes), kernel_size=(1,1), stride = (1,1))\n",
        "# torch.nn.init.xavier_uniform(model.classifier[4].weight)\n",
        "\n",
        "# # print(model.aux_classifier[4])\n",
        "# model.aux_classifier[4] = torch.nn.Conv2d(256, len(classes), kernel_size=(1,1), stride = (1,1))\n",
        "# torch.nn.init.xavier_uniform(model.aux_classifier[4].weight)\n",
        "\n",
        "model.eval()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c9113ab",
      "metadata": {},
      "outputs": [],
      "source": [
        "experiment_name = \"Test33_12_sgd_random_initilization_smallTexT_Custom_small_FCN\" "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "066cdf42",
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "\n",
        "\"\"\"             CUDA Troubleshooting            \"\"\"\n",
        "\n",
        "# %env CUDA_LAUNCH_BLOCKING=1\n",
        "\n",
        "# import torch\n",
        "# torch.backends.cuda.matmul.allow_tf32 = True\n",
        "# torch.backends.cudnn.benchmark = True\n",
        "# torch.backends.cudnn.deterministic = False\n",
        "# torch.backends.cudnn.allow_tf32 = True\n",
        "# data = torch.randn([1, 512, 16, 16], dtype=torch.float, device='cuda', requires_grad=True)\n",
        "# net = torch.nn.Conv2d(512, 1, kernel_size=[1, 1], padding=[0, 0], stride=[1, 1], dilation=[1, 1], groups=1)\n",
        "# net = net.cuda().float()\n",
        "# out = net(data)\n",
        "# out.backward(torch.randn_like(out))\n",
        "# torch.cuda.synchronize()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "accredited-belize",
      "metadata": {
        "id": "accredited-belize"
      },
      "source": [
        "All pre-trained models expect input images normalized in the same way,\n",
        "i.e. mini-batches of 3-channel RGB images of shape `(N, 3, H, W)`, where `N` is the number of images, `H` and `W` are expected to be at least `224` pixels.\n",
        "The images have to be loaded in to a range of `[0, 1]` and then normalized using `mean = [0.485, 0.456, 0.406]`\n",
        "and `std = [0.229, 0.224, 0.225]`.\n",
        "\n",
        "The model returns an `OrderedDict` with two Tensors that are of the same height and width as the input Tensor, but with 21 classes.\n",
        "`output['out']` contains the semantic masks, and `output['aux']` contains the auxillary loss values per-pixel. In inference mode, `output['aux']` is not useful.\n",
        "So, `output['out']` is of shape `(N, 21, H, W)`. More documentation can be found [here](https://pytorch.org/vision/stable/models.html#object-detection-instance-segmentation-and-person-keypoint-detection)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "thirty-crown",
      "metadata": {
        "id": "thirty-crown"
      },
      "outputs": [],
      "source": [
        "import optuna\n",
        "\n",
        "# Select an image from the dataset\n",
        "\n",
        "#TODO change image_with_text_functions.generate_text_on_image_and_pixel_mask_from_path to place the text properly\n",
        "train_dataset = CustomImageDataset(train_data_dir, img_width, img_height)\n",
        "test_dataset = CustomImageDataset(validation_data_dir, img_width, img_height)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Display image and label\n",
        "train_features, train_labels = next(iter(train_dataloader))\n",
        "print(f\"Feature batch shape: {train_features.size()}\")\n",
        "print(f\"Labels batch shape: {train_labels.size()}\")\n",
        "input_image = train_features[0].squeeze()\n",
        "input_image = np.moveaxis(input_image.numpy(), 0, -1)\n",
        "label = train_labels[0].reshape((img_width, img_height))\n",
        "\n",
        "plt.imshow(input_image, cmap=\"gray\")\n",
        "plt.show()\n",
        "plt.imshow(label, cmap=\"gray\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lesbian-vietnamese",
      "metadata": {
        "id": "lesbian-vietnamese"
      },
      "source": [
        "The output here is of shape `(21, H, W)`, and at each location, there are unnormalized probabilities corresponding to the prediction of each class.\n",
        "To get the maximum prediction of each class, and then use it for a downstream task, you can do `output_predictions = output.argmax(0)`.\n",
        "\n",
        "Here's a small snippet that plots the predictions, with each color being assigned to each class (see the visualized image on the left)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "starting-delhi",
      "metadata": {
        "id": "starting-delhi"
      },
      "source": [
        "### Model Description\n",
        "\n",
        "FCN-ResNet is constructed by a Fully-Convolutional Network model, using a ResNet-50 or a ResNet-101 backbone.\n",
        "The pre-trained models have been trained on a subset of COCO train2017, on the 20 categories that are present in the Pascal VOC dataset.\n",
        "\n",
        "Their accuracies of the pre-trained models evaluated on COCO val2017 dataset are listed below.\n",
        "\n",
        "| Model structure |   Mean IOU  | Global Pixelwise Accuracy |\n",
        "| --------------- | ----------- | --------------------------|\n",
        "|  fcn_resnet50   |   60.5      |   91.4                    |\n",
        "|  fcn_resnet101  |   63.7      |   91.9                    |\n",
        "\n",
        "### Resources\n",
        "\n",
        " - [Fully Convolutional Networks for Semantic Segmentation](https://arxiv.org/abs/1605.06211)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "193ad198",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# # pylint: disable = abstract-method\n",
        "# class ModelWrapper(torch.nn.Module):\n",
        "#     \"\"\"\n",
        "#     Wrapper class for model with dict/list rvalues.\n",
        "#     \"\"\"\n",
        "\n",
        "#     def __init__(self, model: torch.nn.Module) -> None:\n",
        "#         \"\"\"\n",
        "#         Init call.\n",
        "#         \"\"\"\n",
        "#         super().__init__()\n",
        "#         self.model = model\n",
        "\n",
        "#     def forward(self, input_x: torch.Tensor) -> Any:\n",
        "#         \"\"\"\n",
        "#         Wrap forward call.\n",
        "#         \"\"\"\n",
        "#         data = self.model(input_x)\n",
        "\n",
        "#         if isinstance(data, dict):\n",
        "#             data_named_tuple = namedtuple(\"ModelEndpoints\", sorted(data.keys()))  # type: ignore\n",
        "#             data = data_named_tuple(**data)  # type: ignore\n",
        "\n",
        "#         elif isinstance(data, list):\n",
        "#             data = tuple(data)\n",
        "\n",
        "#         return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5986e6f8",
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        "# # default `log_dir` is \"runs\" - we'll be more specific here\n",
        "# writer = SummaryWriter('runs/FCN_resnet101_GPU_text_pixel_masking/'+experiment_name) \n",
        "\n",
        "# # get some random training images\n",
        "# dataiter = iter(train_dataloader)\n",
        "# images, labels = dataiter.next()\n",
        "\n",
        "# # create grid of images\n",
        "# img_grid = torchvision.utils.make_grid(images)\n",
        "\n",
        "# # write to tensorboard\n",
        "# writer.add_image('FCN_resnet101_GPU_text_pixel_masking_images', img_grid)\n",
        "\n",
        "# model_wrapper = ModelWrapper(model)\n",
        "# writer = SummaryWriter('runs/FCN_resnet101_GPU_text_pixel_masking/'+experiment_name) \n",
        "\n",
        "# writer.add_graph(model_wrapper, torch.tensor(images))\n",
        "# writer.close()\n",
        "\n",
        "\n",
        "def plot_classes_preds(images, preds, labels):\n",
        "    '''\n",
        "    Generates matplotlib Figure using a trained network, along with images\n",
        "    and labels from a batch, that shows the network's top prediction along\n",
        "    with its probability, alongside the actual label, coloring this\n",
        "    information based on whether the prediction was correct or not.\n",
        "    Uses the \"images_to_probs\" function.\n",
        "    '''\n",
        "\n",
        "    fig = plt.figure(figsize=(30, 15))\n",
        "\n",
        "    fig.add_subplot(1, 3, 1, xticks=[], yticks=[])\n",
        "    input_image = images.squeeze()\n",
        "    # print('input_image', input_image.shape)\n",
        "    plt.imshow(input_image)\n",
        "\n",
        "    fig.add_subplot(1, 3, 2, xticks=[], yticks=[])\n",
        "    plt.imshow(preds.reshape((img_height,img_width)).detach().cpu().numpy(), cmap='gray')\n",
        "\n",
        "    fig.add_subplot(1, 3, 3, xticks=[], yticks=[])\n",
        "    label = labels.reshape((img_width, img_height)).long().detach().cpu()\n",
        "    plt.imshow(label, cmap='gray')\n",
        "\n",
        "\n",
        "    return fig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f449bec8",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "#'model_saves/'+experiment_name+\".pytorch_model\"\n",
        "\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "def validate(num_samples, criterion, writer, epoch, optimizer):\n",
        "    best_val_loss = 0\n",
        "    # Validation\n",
        "\n",
        "    val_loss = 0.0\n",
        "    val_steps = 0\n",
        "    for i, data in enumerate(test_dataloader, 0):\n",
        "        if i > num_samples:\n",
        "            break\n",
        "        with torch.no_grad():\n",
        "            inputs, labels = data\n",
        "            inputs = inputs.squeeze()\n",
        "            inputs = np.moveaxis(inputs.detach().cpu().numpy(), 0, -1)\n",
        "            preprocessed_inputs = cv.cvtColor(inputs, cv.COLOR_BGR2RGB)\n",
        "            preprocessed_inputs = Image.fromarray(np.uint8(preprocessed_inputs))\n",
        "            preprocessed_inputs = preprocessed_inputs.convert(\"RGB\")\n",
        "            preprocessed_inputs = preprocess(preprocessed_inputs)\n",
        "            preprocessed_inputs = preprocessed_inputs.unsqueeze(0)\n",
        "\n",
        "            # move the input and model to GPU for speed if available\n",
        "            if torch.cuda.is_available():\n",
        "                preprocessed_inputs = preprocessed_inputs.to('cuda')\n",
        "                labels = labels.to('cuda')\n",
        "\n",
        "            # forward + backward + optimize\n",
        "            output = model(preprocessed_inputs)[0]\n",
        "            output = nn.Softmax(dim=0)(output)\n",
        "            output = output[1] - output[0]\n",
        "            output = torch.unsqueeze(output, 0)\n",
        "            output = torch.unsqueeze(output, 0)\n",
        "            labels = torch.reshape(labels, (1, img_height,img_width))\n",
        "            labels[labels<=0] = -1\n",
        "            labels[labels>0] = 1\n",
        "            labels = labels.long()\n",
        "\n",
        "            loss = criterion(output, labels)\n",
        "            val_loss += loss.cpu().numpy()    \n",
        "            val_steps += 1\n",
        "\n",
        "        if i % 1000 == 999:    # print every 1000 mini-batches\n",
        "            print(i)\n",
        "            print(\"val loss\", val_loss/val_steps)\n",
        "            writer.add_scalar('average mini-epoch validation loss',\n",
        "                val_loss/val_steps,\n",
        "                val_steps)\n",
        "\n",
        "    writer.add_scalar('average validation loss',\n",
        "            val_loss / val_steps,\n",
        "            epoch)\n",
        "\n",
        "    if val_loss / val_steps < best_val_loss:\n",
        "        print(\"New best model by validation loss!\")\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': loss,\n",
        "            }, 'model_saves/'+experiment_name+\"_\"+str(int(best_val_loss))+\".pytorch_model\")\n",
        "        best_val_loss = val_loss / val_steps\n",
        "        with open(\"model_saves\\\\best_val_loss.txt\", 'a') as best_val_loss_fh:\n",
        "            best_val_loss_fh.write(str(int(best_val_loss))+\"\\n\")\n",
        "        with open(\"model_saves\\\\best_model.txt\", 'a') as best_val_loss_fh:\n",
        "            best_val_loss_fh.write('model_saves/'+experiment_name+\"_\"+str(int(best_val_loss))+\".pytorch_model\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa46e836",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7e2c12f",
      "metadata": {},
      "outputs": [],
      "source": [
        "def objective(trial, model):\n",
        "    \n",
        "    writer = SummaryWriter('runs/FCN_resnet101_GPU_text_pixel_masking/'+experiment_name)#+\"/\"+str(trial.number)) \n",
        "\n",
        "    # criterion = nn.CrossEntropyLoss(size_average=False, reduction='sum')\n",
        "    criterion = nn.SoftMarginLoss(reduction='sum')\n",
        "    # criterion = nn.HingeEmbeddingLoss(margin=1.0, reduction='sum')\n",
        "    optimizer = optim.SGD(model.parameters(), lr=10**-4, momentum=0.99)\n",
        "    if torch.cuda.is_available():\n",
        "        model.to('cuda')\n",
        "    \n",
        "    # optimizer = optim.Adam(model.parameters())\n",
        "    # Test 15 [I 2022-01-25 14:56:49,051] Trial 3 finished with value: 5567.529612823274 and parameters: {'lr': 6.630131189647407e-07, 'beta1': 0.006967112069996084, 'beta2': 0.9853718852556564}. Best is trial 3 with value: 5567.529612823274.\n",
        "    # lr = trial.suggest_loguniform('lr', 10**-8, 10**-4)\n",
        "    # beta1 = trial.suggest_loguniform('beta1', 1e-4, 1)\n",
        "    # beta2 = trial.suggest_loguniform('beta2', 0.8, 0.999)\n",
        "    # print(\"LR trial:\", lr)\n",
        "    # print(\"beta1 trial:\", beta1)\n",
        "    # print(\"beta2 trial:\", beta2)\n",
        "\n",
        "    # optimizer = optim.Adam(model.parameters(), lr=6.630131189647407e-07, betas=(0.006967112069996084, 0.9853718852556564), eps=10**-7) # decided by 5 trials (epochs) of hyperparameter tuning with Optuna\n",
        "    # scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=10**-8, max_lr=10**-4, cycle_momentum=False)\n",
        "    \n",
        "    with open(\"model_saves\\\\best_model.txt\", 'r') as best_model_fh:\n",
        "            lines = best_model_fh.read().splitlines()\n",
        "            if len(lines)>0:\n",
        "                last_line = lines[-1]\n",
        "                best_model_path = last_line\n",
        "            else: \n",
        "                best_model_path = None\n",
        "    if False:\n",
        "        path = best_model_path\n",
        "        checkpoint = torch.load(path)\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "        epoch = checkpoint['epoch']\n",
        "        loss = checkpoint['loss']\n",
        "        print(\"successfully loaded model checkpoint from\", path)\n",
        "\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    # Train the model\n",
        "    last_epoch_loss = 0.0\n",
        "    mini_epoch_loss = 0.0\n",
        "    epoch_loss = 0.0\n",
        "    for epoch in range(50):  # loop over the dataset multiple times  \n",
        "\n",
        "        for i, data in enumerate(train_dataloader, 0):\n",
        "            # get the inputs; data is a list of [inputs, labels]\n",
        "            inputs, labels = data\n",
        "            # print(inputs.shape)\n",
        "\n",
        "            inputs = inputs.squeeze()\n",
        "            inputs = np.moveaxis(inputs.detach().cpu().numpy(), 0, -1)\n",
        "            # print(inputs.shape)\n",
        "            preprocessed_inputs = cv.cvtColor(inputs, cv.COLOR_BGR2RGB)\n",
        "            preprocessed_inputs = Image.fromarray(np.uint8(preprocessed_inputs))\n",
        "            preprocessed_inputs = preprocessed_inputs.convert(\"RGB\")\n",
        "            preprocessed_inputs = preprocess(preprocessed_inputs)\n",
        "            preprocessed_inputs = preprocessed_inputs.unsqueeze(0)\n",
        "\n",
        "            # move the input and model to GPU for speed if available\n",
        "            if torch.cuda.is_available():\n",
        "                preprocessed_inputs = preprocessed_inputs.to('cuda')\n",
        "                labels = labels.to('cuda')\n",
        "                model.to('cuda')\n",
        "                \n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward + backward + optimize\n",
        "            # output = model(preprocessed_inputs)['out'][0]\n",
        "            output = model(preprocessed_inputs)[0]\n",
        "\n",
        "            output = nn.Softmax(dim=0)(output)\n",
        "            output = output[1] - output[0]\n",
        "            # output = torch.unsqueeze(output, 0)\n",
        "            output = torch.unsqueeze(output, 0)\n",
        "            labels = torch.reshape(labels, (1, img_height,img_width))\n",
        "            labels[labels<=0] = -1\n",
        "            labels[labels>0] = 1\n",
        "            labels = labels.long()\n",
        "\n",
        "            loss = criterion(output, labels)\n",
        "            \n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # print statistics\n",
        "            epoch_loss += loss.item()\n",
        "            mini_epoch_loss += loss.item()\n",
        "            if i % 1000 == 999:    # print every 1000 mini-batches\n",
        "            # if i % 100 == 1:    # print every 100 mini-batches\n",
        "            # if i % 2 == 1:    # print every 2 mini-batches\n",
        "                print(i)\n",
        "                print(\"cost\", loss)\n",
        "                                  \n",
        "                writer.add_scalar('average mini-epoch loss',\n",
        "                    mini_epoch_loss / 1000,\n",
        "                    epoch * len(train_dataloader) + i)\n",
        "\n",
        "                mini_epoch_loss = 0.0\n",
        "                writer.add_scalar('most recent cost',\n",
        "                                loss.item(),\n",
        "                                epoch * len(train_dataloader) + i)\n",
        "\n",
        "                # ...log a Matplotlib Figure showing the model's predictions on a\n",
        "                # random mini-batch\n",
        "                writer.add_figure('input vs output vs label',\n",
        "                                plot_classes_preds(inputs, output, labels),\n",
        "                                global_step=epoch * len(train_dataloader) + i) \n",
        "\n",
        "            if i % 5000 == 4999:\n",
        "            # if i % 1 == 0:\n",
        "                validate(3000, criterion, writer, epoch, optimizer)\n",
        "\n",
        "        writer.add_scalar('total epoch loss',\n",
        "                        epoch_loss,\n",
        "                        epoch * len(train_dataloader) + i)\n",
        "        writer.add_scalar('average epoch loss',\n",
        "                         epoch_loss / \n",
        "                        (epoch * len(train_dataloader) + i),\n",
        "                        epoch * len(train_dataloader) + i)\n",
        "\n",
        "\n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "    print('Finished Training')\n",
        "    avg_epoch_loss = epoch_loss / (epoch * len(train_dataloader) + i)\n",
        "    print(\"Average epoch loss of trial:\", avg_epoch_loss)\n",
        "\n",
        "    return avg_epoch_loss #average epoch loss\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25f278d4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# study = optuna.create_study(direction='minimize', study_name=experiment_name)\n",
        "# study.optimize(objective, n_trials=5)\n",
        "\n",
        "objective(None, model)\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f47d3d7",
      "metadata": {},
      "outputs": [],
      "source": [
        "    pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
        "    complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
        "\n",
        "    print(\"Study statistics: \")\n",
        "    print(\"  Number of finished trials: \", len(study.trials))\n",
        "    print(\"  Number of pruned trials: \", len(pruned_trials))\n",
        "    print(\"  Number of complete trials: \", len(complete_trials))\n",
        "\n",
        "    print(\"Best trial:\")\n",
        "    trial = study.best_trial\n",
        "\n",
        "    print(\"  Value: \", trial.value)\n",
        "\n",
        "    print(\"  Params: \")\n",
        "    for key, value in trial.params.items():\n",
        "        print(\"    {}: {}\".format(key, value))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22e90282",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64f2f4b5",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c3be34c",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa9198b1",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a8ebdd9",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e79758fc",
      "metadata": {},
      "outputs": [],
      "source": [
        "def test(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8caa42c6",
      "metadata": {},
      "source": [
        "Show a test of the newly trained (fine tuned) model below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33dad314",
      "metadata": {},
      "outputs": [],
      "source": [
        "model.eval()\n",
        "\n",
        "# Display image and label.\n",
        "test_features, test_labels = next(iter(test_dataloader))\n",
        "print(f\"Feature batch shape: {test_features.size()}\")\n",
        "print(f\"Labels batch shape: {test_labels.size()}\")\n",
        "input_image = test_features[0].squeeze()\n",
        "input_image = np.moveaxis(input_image.numpy(), 0, -1)\n",
        "label = test_labels[0].reshape((img_width, img_height))\n",
        "\n",
        "plt.imshow(input_image, cmap=\"gray\")\n",
        "plt.show()\n",
        "plt.imshow(label, cmap=\"gray\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2f76b07",
      "metadata": {},
      "outputs": [],
      "source": [
        "# input_image = Image.open(filename)\n",
        "input_image2 = cv.cvtColor(input_image, cv.COLOR_BGR2RGB)\n",
        "input_image2 = Image.fromarray(np.uint8(input_image2))\n",
        "input_image2 = input_image2.convert(\"RGB\")\n",
        "\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "input_tensor = preprocess(input_image)\n",
        "input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
        "\n",
        "# move the input and model to GPU for speed if available\n",
        "if torch.cuda.is_available():\n",
        "    input_batch = input_batch.to('cuda')\n",
        "    model.to('cuda')\n",
        "\n",
        "with torch.no_grad():\n",
        "    output = model(input_batch)['out'][0] #zero refers to the batch number?\n",
        "output_predictions = output.argmax(0)\n",
        "print(output_predictions)\n",
        "print(output_predictions.shape)\n",
        "print(output)\n",
        "print(output.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d9d37c0",
      "metadata": {},
      "outputs": [],
      "source": [
        "test(test_dataloader, model, criterion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee44acb2",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "pytorch_vision_fcn_resnet101.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
