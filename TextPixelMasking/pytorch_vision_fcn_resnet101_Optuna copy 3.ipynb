{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "intensive-butter",
      "metadata": {
        "id": "intensive-butter"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "# model = torch.hub.load('pytorch/vision:v0.10.0', 'fcn_resnet50', pretrained=True, )\n",
        "\n",
        "from generate_training_validation_data import CustomImageDataset\n",
        "from Custom_small_FCN import FCN4s\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from PIL import Image\n",
        "import cv2 as cv\n",
        "\n",
        "from collections import namedtuple\n",
        "from typing import Any\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from torchfcn.models import FCN8sAtOnce, VGG16, FCN8s, FCN16s, FCN32s\n",
        "from torchfcn.models.fcn32s import get_upsampling_weight\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "44e60e48",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "class LeakyFCN8sAtOnce(FCN8sAtOnce):\n",
        "    \n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                m.weight.data.zero_()\n",
        "                torch.nn.init.xavier_uniform(m.weight)\n",
        "                if m.bias is not None:\n",
        "                    m.bias.data.zero_()\n",
        "                    torch.nn.init.xavier_uniform(m.bias)\n",
        "\n",
        "            if isinstance(m, nn.ConvTranspose2d):\n",
        "                assert m.kernel_size[0] == m.kernel_size[1]\n",
        "                initial_weight = get_upsampling_weight(\n",
        "                    m.in_channels, m.out_channels, m.kernel_size[0])\n",
        "                m.weight.data.copy_(initial_weight)\n",
        "\n",
        "\n",
        "    def __init__(self, n_class=21):\n",
        "        super(FCN8sAtOnce, self).__init__()\n",
        "        # conv1\n",
        "        self.conv1_1 = nn.Conv2d(3, 64, 3, padding=100)\n",
        "        self.relu1_1 = nn.LeakyReLU(negative_slope=0.03,inplace=True)\n",
        "        self.conv1_2 = nn.Conv2d(64, 64, 3, padding=1)\n",
        "        self.relu1_2 = nn.LeakyReLU(negative_slope=0.03,inplace=True)\n",
        "        self.pool1 = nn.MaxPool2d(2, stride=2, ceil_mode=True)  # 1/2\n",
        "\n",
        "        # conv2\n",
        "        self.conv2_1 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "        self.relu2_1 = nn.LeakyReLU(negative_slope=0.03,inplace=True)\n",
        "        self.conv2_2 = nn.Conv2d(128, 128, 3, padding=1)\n",
        "        self.relu2_2 = nn.LeakyReLU(negative_slope=0.03,inplace=True)\n",
        "        self.pool2 = nn.MaxPool2d(2, stride=2, ceil_mode=True)  # 1/4\n",
        "\n",
        "        # conv3\n",
        "        self.conv3_1 = nn.Conv2d(128, 256, 3, padding=1)\n",
        "        self.relu3_1 = nn.LeakyReLU(negative_slope=0.03,inplace=True)\n",
        "        self.conv3_2 = nn.Conv2d(256, 256, 3, padding=1)\n",
        "        self.relu3_2 = nn.LeakyReLU(negative_slope=0.03,inplace=True)\n",
        "        self.conv3_3 = nn.Conv2d(256, 256, 3, padding=1)\n",
        "        self.relu3_3 = nn.LeakyReLU(negative_slope=0.03,inplace=True)\n",
        "        self.pool3 = nn.MaxPool2d(2, stride=2, ceil_mode=True)  # 1/8\n",
        "\n",
        "        # conv4\n",
        "        self.conv4_1 = nn.Conv2d(256, 512, 3, padding=1)\n",
        "        self.relu4_1 = nn.LeakyReLU(negative_slope=0.03,inplace=True)\n",
        "        self.conv4_2 = nn.Conv2d(512, 512, 3, padding=1)\n",
        "        self.relu4_2 = nn.LeakyReLU(negative_slope=0.03,inplace=True)\n",
        "        self.conv4_3 = nn.Conv2d(512, 512, 3, padding=1)\n",
        "        self.relu4_3 = nn.LeakyReLU(negative_slope=0.03,inplace=True)\n",
        "        self.pool4 = nn.MaxPool2d(2, stride=2, ceil_mode=True)  # 1/16\n",
        "\n",
        "        # conv5\n",
        "        self.conv5_1 = nn.Conv2d(512, 512, 3, padding=1)\n",
        "        self.relu5_1 = nn.LeakyReLU(negative_slope=0.03,inplace=True)\n",
        "        self.conv5_2 = nn.Conv2d(512, 512, 3, padding=1)\n",
        "        self.relu5_2 = nn.LeakyReLU(negative_slope=0.03,inplace=True)\n",
        "        self.conv5_3 = nn.Conv2d(512, 512, 3, padding=1)\n",
        "        self.relu5_3 = nn.LeakyReLU(negative_slope=0.03,inplace=True)\n",
        "        self.pool5 = nn.MaxPool2d(2, stride=2, ceil_mode=True)  # 1/32\n",
        "\n",
        "        # fc6\n",
        "        self.fc6 = nn.Conv2d(512, 4096, 7)\n",
        "        self.relu6 = nn.LeakyReLU(negative_slope=0.03,inplace=True)\n",
        "        self.drop6 = nn.Dropout2d()\n",
        "\n",
        "        # fc7\n",
        "        self.fc7 = nn.Conv2d(4096, 4096, 1)\n",
        "        self.relu7 = nn.LeakyReLU(negative_slope=0.03,inplace=True)\n",
        "        self.drop7 = nn.Dropout2d()\n",
        "\n",
        "        self.score_fr = nn.Conv2d(4096, n_class, 1)\n",
        "        self.score_pool3 = nn.Conv2d(256, n_class, 1)\n",
        "        self.score_pool4 = nn.Conv2d(512, n_class, 1)\n",
        "\n",
        "        self.upscore2 = nn.ConvTranspose2d(\n",
        "            n_class, n_class, 4, stride=2, bias=False)\n",
        "        self.upscore8 = nn.ConvTranspose2d(\n",
        "            n_class, n_class, 16, stride=8, bias=False)\n",
        "        self.upscore_pool4 = nn.ConvTranspose2d(\n",
        "            n_class, n_class, 4, stride=2, bias=False)\n",
        "\n",
        "        self._initialize_weights()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "bb143f6f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[C:\\Users\\maxan/data/models/pytorch/fcn8s_from_caffe.pth] Checking md5 (de93e540ec79512f8770033849c8ae89)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "FCN8s(\n",
              "  (conv1_1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(100, 100))\n",
              "  (relu1_1): ReLU(inplace=True)\n",
              "  (conv1_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (relu1_2): ReLU(inplace=True)\n",
              "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "  (conv2_1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (relu2_1): ReLU(inplace=True)\n",
              "  (conv2_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (relu2_2): ReLU(inplace=True)\n",
              "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "  (conv3_1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (relu3_1): ReLU(inplace=True)\n",
              "  (conv3_2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (relu3_2): ReLU(inplace=True)\n",
              "  (conv3_3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (relu3_3): ReLU(inplace=True)\n",
              "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "  (conv4_1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (relu4_1): ReLU(inplace=True)\n",
              "  (conv4_2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (relu4_2): ReLU(inplace=True)\n",
              "  (conv4_3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (relu4_3): ReLU(inplace=True)\n",
              "  (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "  (conv5_1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (relu5_1): ReLU(inplace=True)\n",
              "  (conv5_2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (relu5_2): ReLU(inplace=True)\n",
              "  (conv5_3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (relu5_3): ReLU(inplace=True)\n",
              "  (pool5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "  (fc6): Conv2d(512, 4096, kernel_size=(7, 7), stride=(1, 1))\n",
              "  (relu6): ReLU(inplace=True)\n",
              "  (drop6): Dropout2d(p=0.5, inplace=False)\n",
              "  (fc7): Conv2d(4096, 4096, kernel_size=(1, 1), stride=(1, 1))\n",
              "  (relu7): ReLU(inplace=True)\n",
              "  (drop7): Dropout2d(p=0.5, inplace=False)\n",
              "  (score_fr): Conv2d(4096, 21, kernel_size=(1, 1), stride=(1, 1))\n",
              "  (score_pool3): Conv2d(256, 21, kernel_size=(1, 1), stride=(1, 1))\n",
              "  (score_pool4): Conv2d(512, 21, kernel_size=(1, 1), stride=(1, 1))\n",
              "  (upscore2): ConvTranspose2d(21, 21, kernel_size=(4, 4), stride=(2, 2), bias=False)\n",
              "  (upscore8): ConvTranspose2d(21, 21, kernel_size=(16, 16), stride=(8, 8), bias=False)\n",
              "  (upscore_pool4): ConvTranspose2d(21, 21, kernel_size=(4, 4), stride=(2, 2), bias=False)\n",
              ")"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "train_data_dir = 'D:/MemeMachine_ProjectData/dataset/training'\n",
        "validation_data_dir = 'D:/MemeMachine_ProjectData/dataset/validation'\n",
        "img_width, img_height, n_channels = 1020, 1020, 3 #TODO change dimensions to be wider, to better support text\n",
        "\n",
        "epochs = 1 #50 TODO\n",
        "batch_size = 1\n",
        "classes = ['nothing', 'text']\n",
        "\n",
        "# model = FCN32s(n_class=len(classes))\n",
        "\n",
        "# vgg16 = VGG16(pretrained=True)\n",
        "# model.copy_params_from_vgg16(vgg16)\n",
        "\n",
        "model = FCN8s()\n",
        "pretrained_model = model.download()\n",
        "model.load_state_dict(torch.load(pretrained_model))\n",
        "\n",
        "# classes = ['text']\n",
        "\n",
        "\n",
        "#change the number of classes in the final step of the classifier\n",
        "# #print(model.classifier[4])\n",
        "# model.classifier[4] = torch.nn.Conv2d(512, len(classes), kernel_size=(1,1), stride = (1,1))\n",
        "# torch.nn.init.xavier_uniform(model.classifier[4].weight)\n",
        "\n",
        "# # #print(model.aux_classifier[4])\n",
        "# model.aux_classifier[4] = torch.nn.Conv2d(256, len(classes), kernel_size=(1,1), stride = (1,1))\n",
        "# torch.nn.init.xavier_uniform(model.aux_classifier[4].weight)\n",
        "\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "0c9113ab",
      "metadata": {},
      "outputs": [],
      "source": [
        "experiment_name = \"Test38_1_pytorch-fcn_FCN8s_Adam\" "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "066cdf42",
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "\n",
        "\"\"\"             CUDA Troubleshooting            \"\"\"\n",
        "\n",
        "def get_parameters(model, bias=False):\n",
        "    import torch.nn as nn\n",
        "    modules_skipped = (\n",
        "        nn.ReLU,\n",
        "        nn.LeakyReLU,\n",
        "        nn.MaxPool2d,\n",
        "        nn.Dropout2d,\n",
        "        nn.Sequential,\n",
        "        FCN32s,\n",
        "        FCN16s,\n",
        "        FCN8s,\n",
        "    )\n",
        "    for m in model.modules():\n",
        "        if isinstance(m, nn.Conv2d):\n",
        "            if bias:\n",
        "                yield m.bias\n",
        "            else:\n",
        "                yield m.weight\n",
        "        elif isinstance(m, nn.ConvTranspose2d):\n",
        "            # weight is frozen because it is just a bilinear upsampling\n",
        "            if bias:\n",
        "                assert m.bias is None\n",
        "        elif isinstance(m, modules_skipped):\n",
        "            continue\n",
        "        else:\n",
        "            raise ValueError('Unexpected module: %s' % str(m))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "accredited-belize",
      "metadata": {
        "id": "accredited-belize"
      },
      "source": [
        "All pre-trained models expect input images normalized in the same way,\n",
        "i.e. mini-batches of 3-channel RGB images of shape `(N, 3, H, W)`, where `N` is the number of images, `H` and `W` are expected to be at least `224` pixels.\n",
        "The images have to be loaded in to a range of `[0, 1]` and then normalized using `mean = [0.485, 0.456, 0.406]`\n",
        "and `std = [0.229, 0.224, 0.225]`.\n",
        "\n",
        "The model returns an `OrderedDict` with two Tensors that are of the same height and width as the input Tensor, but with 21 classes.\n",
        "`output['out']` contains the semantic masks, and `output['aux']` contains the auxillary loss values per-pixel. In inference mode, `output['aux']` is not useful.\n",
        "So, `output['out']` is of shape `(N, 21, H, W)`. More documentation can be found [here](https://pytorch.org/vision/stable/models.html#object-detection-instance-segmentation-and-person-keypoint-detection)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "thirty-crown",
      "metadata": {
        "id": "thirty-crown"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import optuna\n",
        "\n",
        "# Select an image from the dataset\n",
        "\n",
        "#TODO change image_with_text_functions.generate_text_on_image_and_pixel_mask_from_path to place the text properly\n",
        "train_dataset = CustomImageDataset(train_data_dir, img_width, img_height)\n",
        "test_dataset = CustomImageDataset(validation_data_dir, img_width, img_height)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Display image and label\n",
        "train_features, train_labels = next(iter(train_dataloader))\n",
        "#print(f\"Feature batch shape: {train_features.size()}\")\n",
        "#print(f\"Labels batch shape: {train_labels.size()}\")\n",
        "input_image = train_features[0].squeeze()\n",
        "input_image = np.moveaxis(input_image.numpy(), 0, -1)\n",
        "label = train_labels[0].reshape((img_width, img_height))\n",
        "\n",
        "plt.imshow(input_image, cmap=\"gray\")\n",
        "plt.show()\n",
        "plt.imshow(label, cmap=\"gray\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lesbian-vietnamese",
      "metadata": {
        "id": "lesbian-vietnamese"
      },
      "source": [
        "The output here is of shape `(21, H, W)`, and at each location, there are unnormalized probabilities corresponding to the prediction of each class.\n",
        "To get the maximum prediction of each class, and then use it for a downstream task, you can do `output_predictions = output.argmax(0)`.\n",
        "\n",
        "Here's a small snippet that plots the predictions, with each color being assigned to each class (see the visualized image on the left)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "starting-delhi",
      "metadata": {
        "id": "starting-delhi"
      },
      "source": [
        "### Model Description\n",
        "\n",
        "FCN-ResNet is constructed by a Fully-Convolutional Network model, using a ResNet-50 or a ResNet-101 backbone.\n",
        "The pre-trained models have been trained on a subset of COCO train2017, on the 20 categories that are present in the Pascal VOC dataset.\n",
        "\n",
        "Their accuracies of the pre-trained models evaluated on COCO val2017 dataset are listed below.\n",
        "\n",
        "| Model structure |   Mean IOU  | Global Pixelwise Accuracy |\n",
        "| --------------- | ----------- | --------------------------|\n",
        "|  fcn_resnet50   |   60.5      |   91.4                    |\n",
        "|  fcn_resnet101  |   63.7      |   91.9                    |\n",
        "\n",
        "### Resources\n",
        "\n",
        " - [Fully Convolutional Networks for Semantic Segmentation](https://arxiv.org/abs/1605.06211)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "193ad198",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# # pylint: disable = abstract-method\n",
        "# class ModelWrapper(torch.nn.Module):\n",
        "#     \"\"\"\n",
        "#     Wrapper class for model with dict/list rvalues.\n",
        "#     \"\"\"\n",
        "\n",
        "#     def __init__(self, model: torch.nn.Module) -> None:\n",
        "#         \"\"\"\n",
        "#         Init call.\n",
        "#         \"\"\"\n",
        "#         super().__init__()\n",
        "#         self.model = model\n",
        "\n",
        "#     def forward(self, input_x: torch.Tensor) -> Any:\n",
        "#         \"\"\"\n",
        "#         Wrap forward call.\n",
        "#         \"\"\"\n",
        "#         data = self.model(input_x)\n",
        "\n",
        "#         if isinstance(data, dict):\n",
        "#             data_named_tuple = namedtuple(\"ModelEndpoints\", sorted(data.keys()))  # type: ignore\n",
        "#             data = data_named_tuple(**data)  # type: ignore\n",
        "\n",
        "#         elif isinstance(data, list):\n",
        "#             data = tuple(data)\n",
        "\n",
        "#         return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "5986e6f8",
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        "# # default `log_dir` is \"runs\" - we'll be more specific here\n",
        "# writer = SummaryWriter('runs/FCN_resnet101_GPU_text_pixel_masking/'+experiment_name) \n",
        "\n",
        "# # get some random training images\n",
        "# dataiter = iter(train_dataloader)\n",
        "# images, labels = dataiter.next()\n",
        "\n",
        "# # create grid of images\n",
        "# img_grid = torchvision.utils.make_grid(images)\n",
        "\n",
        "# # write to tensorboard\n",
        "# writer.add_image('FCN_resnet101_GPU_text_pixel_masking_images', img_grid)\n",
        "\n",
        "# model_wrapper = ModelWrapper(model)\n",
        "# writer = SummaryWriter('runs/FCN_resnet101_GPU_text_pixel_masking/'+experiment_name) \n",
        "\n",
        "# writer.add_graph(model_wrapper, torch.tensor(images))\n",
        "# writer.close()\n",
        "\n",
        "\n",
        "def plot_classes_preds(images, preds, labels):\n",
        "    '''\n",
        "    Generates matplotlib Figure using a trained network, along with images\n",
        "    and labels from a batch, that shows the network's top prediction along\n",
        "    with its probability, alongside the actual label, coloring this\n",
        "    information based on whether the prediction was correct or not.\n",
        "    Uses the \"images_to_probs\" function.\n",
        "    '''\n",
        "\n",
        "    images = images.detach().cpu().numpy().squeeze()\n",
        "    print(images.shape)\n",
        "    images = images.transpose((1,2,0))\n",
        "\n",
        "\n",
        "\n",
        "    fig = plt.figure(figsize=(30, 15))\n",
        "\n",
        "    fig.add_subplot(1, 3, 1, xticks=[], yticks=[])\n",
        "    input_image = images.squeeze()\n",
        "    # #print('input_image', input_image.shape)\n",
        "    plt.imshow(input_image)\n",
        "\n",
        "    fig.add_subplot(1, 3, 2, xticks=[], yticks=[])\n",
        "    plt.imshow(preds.reshape((img_height,img_width)).detach().cpu().numpy(), cmap='gray')\n",
        "\n",
        "    fig.add_subplot(1, 3, 3, xticks=[], yticks=[])\n",
        "    label = labels.reshape((img_width, img_height)).long().detach().cpu()\n",
        "    plt.imshow(label, cmap='gray')\n",
        "\n",
        "\n",
        "    return fig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "f449bec8",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "#'model_saves/'+experiment_name+\".pytorch_model\"\n",
        "\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "def validate(num_samples, criterion, writer, epoch, optimizer):\n",
        "    best_val_loss = 0\n",
        "    # Validation\n",
        "\n",
        "    val_loss = 0.0\n",
        "    val_steps = 0\n",
        "    for i, data in enumerate(test_dataloader, 0):\n",
        "        if i > num_samples:\n",
        "            break\n",
        "        with torch.no_grad():\n",
        "            inputs, labels = data\n",
        "            inputs = inputs.squeeze()\n",
        "            inputs = np.moveaxis(inputs.detach().cpu().numpy(), 0, -1)\n",
        "            preprocessed_inputs = cv.cvtColor(inputs, cv.COLOR_BGR2RGB)\n",
        "            preprocessed_inputs = Image.fromarray(np.uint8(preprocessed_inputs))\n",
        "            preprocessed_inputs = preprocessed_inputs.convert(\"RGB\")\n",
        "            preprocessed_inputs = preprocess(preprocessed_inputs)\n",
        "            preprocessed_inputs = preprocessed_inputs.unsqueeze(0)\n",
        "\n",
        "            # move the input and model to GPU for speed if available\n",
        "            if torch.cuda.is_available():\n",
        "                preprocessed_inputs = preprocessed_inputs.to('cuda')\n",
        "                labels = labels.to('cuda')\n",
        "\n",
        "            # forward + backward + optimize\n",
        "            output = model(preprocessed_inputs)[0]\n",
        "            output = nn.Softmax(dim=0)(output)\n",
        "            output = output[1] - output[0]\n",
        "            output = torch.unsqueeze(output, 0)\n",
        "            output = torch.unsqueeze(output, 0)\n",
        "            labels = torch.reshape(labels, (1, img_height,img_width))\n",
        "            labels[labels<=0] = -1\n",
        "            labels[labels>0] = 1\n",
        "            labels = labels.long()\n",
        "\n",
        "            loss = criterion(output, labels)\n",
        "            val_loss += loss.cpu().numpy()    \n",
        "            val_steps += 1\n",
        "\n",
        "        if i % 1000 == 999:    # #print every 1000 mini-batches\n",
        "            #print(i)\n",
        "            #print(\"val loss\", val_loss/val_steps)\n",
        "            writer.add_scalar('average mini-epoch validation loss',\n",
        "                val_loss/val_steps,\n",
        "                val_steps)\n",
        "\n",
        "    writer.add_scalar('average validation loss',\n",
        "            val_loss / val_steps,\n",
        "            epoch)\n",
        "\n",
        "    if val_loss / val_steps < best_val_loss:\n",
        "        #print(\"New best model by validation loss!\")\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': loss,\n",
        "            }, 'model_saves/'+experiment_name+\"_\"+str(int(best_val_loss))+\".pytorch_model\")\n",
        "        best_val_loss = val_loss / val_steps\n",
        "        with open(\"model_saves\\\\best_val_loss.txt\", 'a') as best_val_loss_fh:\n",
        "            best_val_loss_fh.write(str(int(best_val_loss))+\"\\n\")\n",
        "        with open(\"model_saves\\\\best_model.txt\", 'a') as best_val_loss_fh:\n",
        "            best_val_loss_fh.write('model_saves/'+experiment_name+\"_\"+str(int(best_val_loss))+\".pytorch_model\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "c7e2c12f",
      "metadata": {},
      "outputs": [],
      "source": [
        "def objective(trial, model):\n",
        "    \n",
        "    writer = SummaryWriter('runs/FCN_resnet101_GPU_text_pixel_masking/'+experiment_name)#+\"/\"+str(trial.number)) \n",
        "\n",
        "    # criterion = nn.CrossEntropyLoss(size_average=False, reduction='sum')\n",
        "    criterion = nn.SoftMarginLoss(reduction='sum')\n",
        "    # criterion = nn.HingeEmbeddingLoss(margin=1.0, reduction='sum')\n",
        "    # optimizer = optim.SGD(model.parameters(), lr=10**-4, momentum=0.99)\n",
        "\n",
        "    # optimizer = torch.optim.SGD(\n",
        "    #     [\n",
        "    #         {'params': get_parameters(model, bias=False)},\n",
        "    #         {'params': get_parameters(model, bias=True),\n",
        "    #          'lr':(10**-10)* 2, 'weight_decay': 0},\n",
        "    #     ],\n",
        "    #     lr=(10**-10),\n",
        "    #     momentum=0.99)\n",
        "    if torch.cuda.is_available():\n",
        "        model.to('cuda')\n",
        "    \n",
        "    # optimizer = optim.Adam(model.parameters())\n",
        "        optimizer = torch.optim.Adam(\n",
        "        [\n",
        "            {'params': get_parameters(model, bias=False)},\n",
        "            {'params': get_parameters(model, bias=True),\n",
        "             'lr': 0.006967112069996084, 'beta1': 0.006967112069996084, 'beta2': 0.9853718852556564},\n",
        "        ])\n",
        "    # Test 15 [I 2022-01-25 14:56:49,051] Trial 3 finished with value: 5567.529612823274 and parameters: {'lr': 6.630131189647407e-07, 'beta1': 0.006967112069996084, 'beta2': 0.9853718852556564}. Best is trial 3 with value: 5567.529612823274.\n",
        "    # lr = trial.suggest_loguniform('lr', 10**-8, 10**-4)\n",
        "    # beta1 = trial.suggest_loguniform('beta1', 1e-4, 1)\n",
        "    # beta2 = trial.suggest_loguniform('beta2', 0.8, 0.999)\n",
        "    # print(\"LR trial:\", lr)\n",
        "    # print(\"beta1 trial:\", beta1)\n",
        "    # print(\"beta2 trial:\", beta2)\n",
        "\n",
        "    # optimizer = optim.Adam(model.parameters(), lr=6.630131189647407e-07, betas=(0.006967112069996084, 0.9853718852556564), eps=10**-7) # decided by 5 trials (epochs) of hyperparameter tuning with Optuna\n",
        "    # scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=10**-8, max_lr=10**-4, cycle_momentum=False)\n",
        "    \n",
        "    with open(\"model_saves\\\\best_model.txt\", 'r') as best_model_fh:\n",
        "            lines = best_model_fh.read().splitlines()\n",
        "            if len(lines)>0:\n",
        "                last_line = lines[-1]\n",
        "                best_model_path = last_line\n",
        "            else: \n",
        "                best_model_path = None\n",
        "    if False:\n",
        "        path = best_model_path\n",
        "        checkpoint = torch.load(path)\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "        epoch = checkpoint['epoch']\n",
        "        loss = checkpoint['loss']\n",
        "        print(\"successfully loaded model checkpoint from\", path)\n",
        "\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    # Train the model\n",
        "    last_epoch_loss = 0.0\n",
        "    mini_epoch_loss = 0.0\n",
        "    epoch_loss = 0.0\n",
        "    for epoch in range(50):  # loop over the dataset multiple times  \n",
        "\n",
        "        for i, data in enumerate(train_dataloader, 0):\n",
        "            # get the inputs; data is a list of [inputs, labels]\n",
        "            inputs, labels = data\n",
        "            # print(inputs.shape)\n",
        "\n",
        "            # inputs = inputs.squeeze()\n",
        "            # inputs = np.moveaxis(inputs.detach().cpu().numpy(), 0, -1)\n",
        "            # # print(inputs.shape)\n",
        "            # preprocessed_inputs = cv.cvtColor(inputs, cv.COLOR_BGR2RGB)\n",
        "            # preprocessed_inputs = Image.fromarray(np.uint8(preprocessed_inputs))\n",
        "            # preprocessed_inputs = preprocessed_inputs.convert(\"RGB\")\n",
        "            # preprocessed_inputs = preprocess(preprocessed_inputs)\n",
        "            # preprocessed_inputs = preprocessed_inputs.unsqueeze(0)\n",
        "\n",
        "            # move the input and model to GPU for speed if available\n",
        "            if torch.cuda.is_available():\n",
        "                preprocessed_inputs = inputs.to('cuda')\n",
        "                labels = labels.to('cuda')\n",
        "                model.to('cuda')\n",
        "                \n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward + backward + optimize\n",
        "            # output = model(preprocessed_inputs)['out'][0]\n",
        "            output = model(preprocessed_inputs)\n",
        "            print(\"raw_output1 max\", torch.max(output))\n",
        "            print(\"raw_output1 shape\", output.shape)\n",
        "\n",
        "            output = output[0]\n",
        "            print(\"raw_output21 max\", torch.max(output[0]))\n",
        "            print(\"raw_output22 max\", torch.max(output[1]))\n",
        "            print(\"raw_output2 shape\", output.shape)\n",
        "\n",
        "            output = nn.Softmax(dim=0)(output)\n",
        "            print(\"softmax_output max\", torch.max(output))\n",
        "            print(\"softmax_output min\", torch.min(output))\n",
        "\n",
        "            print(\"softmax_output[0] max\", torch.max(output[0]))\n",
        "            print(\"softmax_output[0] min\", torch.min(output[0]))\n",
        "            print(\"softmax_output[0] shape\", output[0].shape)\n",
        "\n",
        "            \n",
        "            print(\"softmax_output[1] max\", torch.max(output[1]))\n",
        "            print(\"softmax_output[1] min\", torch.min(output[1]))\n",
        "            print(\"softmax_output[1] shape\", output[1].shape)\n",
        "\n",
        "            output = output[1] - output[0]\n",
        "            output = torch.unsqueeze(output, 0)\n",
        "            print(\"finaloutput\", output)\n",
        "            print(\"finalputput shape\", output.shape)\n",
        "\n",
        "\n",
        "\n",
        "            output = torch.unsqueeze(output, 0)\n",
        "            labels = torch.reshape(labels, (1, img_height,img_width))\n",
        "            labels[labels<=0] = -1\n",
        "            labels[labels>0] = 1\n",
        "            labels = labels.long()\n",
        "\n",
        "            loss = criterion(output, labels)\n",
        "            \n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # print statistics\n",
        "            epoch_loss += loss.item()\n",
        "            mini_epoch_loss += loss.item()\n",
        "            # if i % 1000 == 999:    # print every 1000 mini-batches\n",
        "            # if i % 100 == 1:    # print every 100 mini-batches\n",
        "            if i % 2 == 1:    # print every 2 mini-batches\n",
        "                print(i)\n",
        "                print(\"cost\", loss)\n",
        "                                  \n",
        "                writer.add_scalar('average mini-epoch loss',\n",
        "                    mini_epoch_loss / 1000,\n",
        "                    epoch * len(train_dataloader) + i)\n",
        "\n",
        "                mini_epoch_loss = 0.0\n",
        "                writer.add_scalar('most recent cost',\n",
        "                                loss.item(),\n",
        "                                epoch * len(train_dataloader) + i)\n",
        "\n",
        "                # ...log a Matplotlib Figure showing the model's predictions on a\n",
        "                # random mini-batch\n",
        "                writer.add_figure('input vs output vs label',\n",
        "                                plot_classes_preds(inputs, output, labels),\n",
        "                                global_step=epoch * len(train_dataloader) + i) \n",
        "\n",
        "            if i % 5000 == 4999:\n",
        "            # if i % 1 == 0:\n",
        "                validate(3000, criterion, writer, epoch, optimizer)\n",
        "\n",
        "        writer.add_scalar('total epoch loss',\n",
        "                        epoch_loss,\n",
        "                        epoch * len(train_dataloader) + i)\n",
        "        writer.add_scalar('average epoch loss',\n",
        "                         epoch_loss / \n",
        "                        (epoch * len(train_dataloader) + i),\n",
        "                        epoch * len(train_dataloader) + i)\n",
        "\n",
        "\n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "    print('Finished Training')\n",
        "    avg_epoch_loss = epoch_loss / (epoch * len(train_dataloader) + i)\n",
        "    print(\"Average epoch loss of trial:\", avg_epoch_loss)\n",
        "\n",
        "    return avg_epoch_loss #average epoch loss\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "25f278d4",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "raw_output1 max tensor(20.6640, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output1 shape torch.Size([1, 21, 1020, 1020])\n",
            "raw_output21 max tensor(20.6640, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output22 max tensor(8.3896, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output2 shape torch.Size([21, 1020, 1020])\n",
            "softmax_output max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output min tensor(6.0485e-12, device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[0] min tensor(0.5468, device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] shape torch.Size([1020, 1020])\n",
            "softmax_output[1] max tensor(0.3727, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[1] min tensor(4.0395e-10, device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[1] shape torch.Size([1020, 1020])\n",
            "finaloutput tensor([[[-0.9917, -0.9935, -0.9952,  ..., -0.9996, -0.9997, -0.9997],\n",
            "         [-0.9934, -0.9950, -0.9963,  ..., -0.9997, -0.9998, -0.9998],\n",
            "         [-0.9948, -0.9961, -0.9972,  ..., -0.9998, -0.9998, -0.9999],\n",
            "         ...,\n",
            "         [-0.9961, -0.9970, -0.9977,  ..., -0.9999, -0.9999, -0.9999],\n",
            "         [-0.9968, -0.9976, -0.9981,  ..., -0.9999, -0.9999, -0.9999],\n",
            "         [-0.9973, -0.9980, -0.9984,  ..., -0.9999, -0.9999, -1.0000]]],\n",
            "       device='cuda:0', grad_fn=<UnsqueezeBackward0>)\n",
            "finalputput shape torch.Size([1, 1020, 1020])\n",
            "raw_output1 max tensor(4596.2412, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output1 shape torch.Size([1, 21, 1020, 1020])\n",
            "raw_output21 max tensor(4309.6431, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output22 max tensor(4596.2412, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output2 shape torch.Size([21, 1020, 1020])\n",
            "softmax_output max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[0] min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] shape torch.Size([1020, 1020])\n",
            "softmax_output[1] max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[1] min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[1] shape torch.Size([1020, 1020])\n",
            "finaloutput tensor([[[1., 1., 1.,  ..., 1., 1., 1.],\n",
            "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "         ...,\n",
            "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "         [1., 1., 1.,  ..., 1., 1., 1.]]], device='cuda:0',\n",
            "       grad_fn=<UnsqueezeBackward0>)\n",
            "finalputput shape torch.Size([1, 1020, 1020])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n",
            "cost tensor(662522.7500, device='cuda:0', grad_fn=<SoftMarginLossBackward0>)\n",
            "(3, 1020, 1020)\n",
            "raw_output1 max tensor(310866.5000, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output1 shape torch.Size([1, 21, 1020, 1020])\n",
            "raw_output21 max tensor(310866.5000, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output22 max tensor(-2123.1738, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output2 shape torch.Size([21, 1020, 1020])\n",
            "softmax_output max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[0] min tensor(1., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] shape torch.Size([1020, 1020])\n",
            "softmax_output[1] max tensor(0., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[1] min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[1] shape torch.Size([1020, 1020])\n",
            "finaloutput tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         ...,\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.]]], device='cuda:0',\n",
            "       grad_fn=<UnsqueezeBackward0>)\n",
            "finalputput shape torch.Size([1, 1020, 1020])\n",
            "raw_output1 max tensor(6260727., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output1 shape torch.Size([1, 21, 1020, 1020])\n",
            "raw_output21 max tensor(6260727., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output22 max tensor(-109166.7891, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output2 shape torch.Size([21, 1020, 1020])\n",
            "softmax_output max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[0] min tensor(1., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] shape torch.Size([1020, 1020])\n",
            "softmax_output[1] max tensor(0., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[1] min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[1] shape torch.Size([1020, 1020])\n",
            "finaloutput tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         ...,\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.]]], device='cuda:0',\n",
            "       grad_fn=<UnsqueezeBackward0>)\n",
            "finalputput shape torch.Size([1, 1020, 1020])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3\n",
            "cost tensor(388495.5000, device='cuda:0', grad_fn=<SoftMarginLossBackward0>)\n",
            "(3, 1020, 1020)\n",
            "raw_output1 max tensor(80279832., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output1 shape torch.Size([1, 21, 1020, 1020])\n",
            "raw_output21 max tensor(80279832., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output22 max tensor(-1050989., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output2 shape torch.Size([21, 1020, 1020])\n",
            "softmax_output max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[0] min tensor(1., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] shape torch.Size([1020, 1020])\n",
            "softmax_output[1] max tensor(0., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[1] min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[1] shape torch.Size([1020, 1020])\n",
            "finaloutput tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         ...,\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.]]], device='cuda:0',\n",
            "       grad_fn=<UnsqueezeBackward0>)\n",
            "finalputput shape torch.Size([1, 1020, 1020])\n",
            "raw_output1 max tensor(5.5100e+08, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output1 shape torch.Size([1, 21, 1020, 1020])\n",
            "raw_output21 max tensor(5.5100e+08, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output22 max tensor(-6438495.5000, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output2 shape torch.Size([21, 1020, 1020])\n",
            "softmax_output max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[0] min tensor(1., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] shape torch.Size([1020, 1020])\n",
            "softmax_output[1] max tensor(0., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[1] min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[1] shape torch.Size([1020, 1020])\n",
            "finaloutput tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         ...,\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.]]], device='cuda:0',\n",
            "       grad_fn=<UnsqueezeBackward0>)\n",
            "finalputput shape torch.Size([1, 1020, 1020])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5\n",
            "cost tensor(381040.5000, device='cuda:0', grad_fn=<SoftMarginLossBackward0>)\n",
            "(3, 1020, 1020)\n",
            "raw_output1 max tensor(1.8629e+09, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output1 shape torch.Size([1, 21, 1020, 1020])\n",
            "raw_output21 max tensor(1.8629e+09, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output22 max tensor(-24135072., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output2 shape torch.Size([21, 1020, 1020])\n",
            "softmax_output max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[0] min tensor(1., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] shape torch.Size([1020, 1020])\n",
            "softmax_output[1] max tensor(0., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[1] min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[1] shape torch.Size([1020, 1020])\n",
            "finaloutput tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         ...,\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.]]], device='cuda:0',\n",
            "       grad_fn=<UnsqueezeBackward0>)\n",
            "finalputput shape torch.Size([1, 1020, 1020])\n",
            "raw_output1 max tensor(5.5639e+09, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output1 shape torch.Size([1, 21, 1020, 1020])\n",
            "raw_output21 max tensor(5.5639e+09, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output22 max tensor(-26927320., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output2 shape torch.Size([21, 1020, 1020])\n",
            "softmax_output max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[0] min tensor(1., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] shape torch.Size([1020, 1020])\n",
            "softmax_output[1] max tensor(0., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[1] min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[1] shape torch.Size([1020, 1020])\n",
            "finaloutput tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         ...,\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.]]], device='cuda:0',\n",
            "       grad_fn=<UnsqueezeBackward0>)\n",
            "finalputput shape torch.Size([1, 1020, 1020])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7\n",
            "cost tensor(363749.5000, device='cuda:0', grad_fn=<SoftMarginLossBackward0>)\n",
            "(3, 1020, 1020)\n",
            "raw_output1 max tensor(1.2846e+10, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output1 shape torch.Size([1, 21, 1020, 1020])\n",
            "raw_output21 max tensor(1.2846e+10, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output22 max tensor(-1.7817e+08, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output2 shape torch.Size([21, 1020, 1020])\n",
            "softmax_output max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[0] min tensor(1., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] shape torch.Size([1020, 1020])\n",
            "softmax_output[1] max tensor(0., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[1] min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[1] shape torch.Size([1020, 1020])\n",
            "finaloutput tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         ...,\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.]]], device='cuda:0',\n",
            "       grad_fn=<UnsqueezeBackward0>)\n",
            "finalputput shape torch.Size([1, 1020, 1020])\n",
            "raw_output1 max tensor(2.9549e+10, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output1 shape torch.Size([1, 21, 1020, 1020])\n",
            "raw_output21 max tensor(2.9549e+10, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output22 max tensor(-1.9984e+08, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output2 shape torch.Size([21, 1020, 1020])\n",
            "softmax_output max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[0] min tensor(1., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] shape torch.Size([1020, 1020])\n",
            "softmax_output[1] max tensor(0., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[1] min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[1] shape torch.Size([1020, 1020])\n",
            "finaloutput tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         ...,\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.]]], device='cuda:0',\n",
            "       grad_fn=<UnsqueezeBackward0>)\n",
            "finalputput shape torch.Size([1, 1020, 1020])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9\n",
            "cost tensor(406032.5000, device='cuda:0', grad_fn=<SoftMarginLossBackward0>)\n",
            "(3, 1020, 1020)\n",
            "raw_output1 max tensor(6.5636e+10, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output1 shape torch.Size([1, 21, 1020, 1020])\n",
            "raw_output21 max tensor(6.5636e+10, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output22 max tensor(-7.4852e+08, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output2 shape torch.Size([21, 1020, 1020])\n",
            "softmax_output max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[0] min tensor(1., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] shape torch.Size([1020, 1020])\n",
            "softmax_output[1] max tensor(0., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[1] min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[1] shape torch.Size([1020, 1020])\n",
            "finaloutput tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         ...,\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.]]], device='cuda:0',\n",
            "       grad_fn=<UnsqueezeBackward0>)\n",
            "finalputput shape torch.Size([1, 1020, 1020])\n",
            "raw_output1 max tensor(8.4096e+10, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output1 shape torch.Size([1, 21, 1020, 1020])\n",
            "raw_output21 max tensor(8.4096e+10, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output22 max tensor(-1.6624e+09, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output2 shape torch.Size([21, 1020, 1020])\n",
            "softmax_output max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[0] min tensor(1., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] shape torch.Size([1020, 1020])\n",
            "softmax_output[1] max tensor(0., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[1] min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[1] shape torch.Size([1020, 1020])\n",
            "finaloutput tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         ...,\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.]]], device='cuda:0',\n",
            "       grad_fn=<UnsqueezeBackward0>)\n",
            "finalputput shape torch.Size([1, 1020, 1020])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "11\n",
            "cost tensor(339804.5000, device='cuda:0', grad_fn=<SoftMarginLossBackward0>)\n",
            "(3, 1020, 1020)\n",
            "raw_output1 max tensor(1.3859e+11, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output1 shape torch.Size([1, 21, 1020, 1020])\n",
            "raw_output21 max tensor(1.3859e+11, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output22 max tensor(-1.8248e+09, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output2 shape torch.Size([21, 1020, 1020])\n",
            "softmax_output max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[0] min tensor(1., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] shape torch.Size([1020, 1020])\n",
            "softmax_output[1] max tensor(0., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[1] min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[1] shape torch.Size([1020, 1020])\n",
            "finaloutput tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         ...,\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.]]], device='cuda:0',\n",
            "       grad_fn=<UnsqueezeBackward0>)\n",
            "finalputput shape torch.Size([1, 1020, 1020])\n",
            "raw_output1 max tensor(2.1219e+11, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output1 shape torch.Size([1, 21, 1020, 1020])\n",
            "raw_output21 max tensor(2.1219e+11, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output22 max tensor(-3.6008e+09, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output2 shape torch.Size([21, 1020, 1020])\n",
            "softmax_output max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[0] min tensor(1., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] shape torch.Size([1020, 1020])\n",
            "softmax_output[1] max tensor(0., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[1] min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[1] shape torch.Size([1020, 1020])\n",
            "finaloutput tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         ...,\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.]]], device='cuda:0',\n",
            "       grad_fn=<UnsqueezeBackward0>)\n",
            "finalputput shape torch.Size([1, 1020, 1020])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "13\n",
            "cost tensor(335639.5000, device='cuda:0', grad_fn=<SoftMarginLossBackward0>)\n",
            "(3, 1020, 1020)\n",
            "raw_output1 max tensor(3.1576e+11, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output1 shape torch.Size([1, 21, 1020, 1020])\n",
            "raw_output21 max tensor(3.1576e+11, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output22 max tensor(-5.0560e+09, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output2 shape torch.Size([21, 1020, 1020])\n",
            "softmax_output max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[0] min tensor(1., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] shape torch.Size([1020, 1020])\n",
            "softmax_output[1] max tensor(0., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[1] min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[1] shape torch.Size([1020, 1020])\n",
            "finaloutput tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         ...,\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.]]], device='cuda:0',\n",
            "       grad_fn=<UnsqueezeBackward0>)\n",
            "finalputput shape torch.Size([1, 1020, 1020])\n",
            "raw_output1 max tensor(3.1227e+11, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output1 shape torch.Size([1, 21, 1020, 1020])\n",
            "raw_output21 max tensor(3.1227e+11, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output22 max tensor(-8.4398e+09, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output2 shape torch.Size([21, 1020, 1020])\n",
            "softmax_output max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[0] min tensor(1., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] shape torch.Size([1020, 1020])\n",
            "softmax_output[1] max tensor(0., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[1] min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[1] shape torch.Size([1020, 1020])\n",
            "finaloutput tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         ...,\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.]]], device='cuda:0',\n",
            "       grad_fn=<UnsqueezeBackward0>)\n",
            "finalputput shape torch.Size([1, 1020, 1020])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "15\n",
            "cost tensor(327395.5000, device='cuda:0', grad_fn=<SoftMarginLossBackward0>)\n",
            "(3, 1020, 1020)\n",
            "raw_output1 max tensor(5.2823e+11, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output1 shape torch.Size([1, 21, 1020, 1020])\n",
            "raw_output21 max tensor(5.2823e+11, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output22 max tensor(-7.5377e+09, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output2 shape torch.Size([21, 1020, 1020])\n",
            "softmax_output max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[0] min tensor(1., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] shape torch.Size([1020, 1020])\n",
            "softmax_output[1] max tensor(0., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[1] min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[1] shape torch.Size([1020, 1020])\n",
            "finaloutput tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         ...,\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.]]], device='cuda:0',\n",
            "       grad_fn=<UnsqueezeBackward0>)\n",
            "finalputput shape torch.Size([1, 1020, 1020])\n",
            "raw_output1 max tensor(9.8059e+11, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output1 shape torch.Size([1, 21, 1020, 1020])\n",
            "raw_output21 max tensor(9.8059e+11, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output22 max tensor(-2.0663e+10, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output2 shape torch.Size([21, 1020, 1020])\n",
            "softmax_output max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[0] min tensor(1., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] shape torch.Size([1020, 1020])\n",
            "softmax_output[1] max tensor(0., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[1] min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[1] shape torch.Size([1020, 1020])\n",
            "finaloutput tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         ...,\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.]]], device='cuda:0',\n",
            "       grad_fn=<UnsqueezeBackward0>)\n",
            "finalputput shape torch.Size([1, 1020, 1020])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "17\n",
            "cost tensor(341263.5000, device='cuda:0', grad_fn=<SoftMarginLossBackward0>)\n",
            "(3, 1020, 1020)\n",
            "raw_output1 max tensor(1.1014e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output1 shape torch.Size([1, 21, 1020, 1020])\n",
            "raw_output21 max tensor(1.1014e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output22 max tensor(-1.8657e+10, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output2 shape torch.Size([21, 1020, 1020])\n",
            "softmax_output max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[0] min tensor(1., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] shape torch.Size([1020, 1020])\n",
            "softmax_output[1] max tensor(0., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[1] min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[1] shape torch.Size([1020, 1020])\n",
            "finaloutput tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         ...,\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.]]], device='cuda:0',\n",
            "       grad_fn=<UnsqueezeBackward0>)\n",
            "finalputput shape torch.Size([1, 1020, 1020])\n",
            "raw_output1 max tensor(1.3554e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output1 shape torch.Size([1, 21, 1020, 1020])\n",
            "raw_output21 max tensor(1.3554e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output22 max tensor(-1.8395e+10, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output2 shape torch.Size([21, 1020, 1020])\n",
            "softmax_output max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[0] min tensor(1., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] shape torch.Size([1020, 1020])\n",
            "softmax_output[1] max tensor(0., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[1] min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[1] shape torch.Size([1020, 1020])\n",
            "finaloutput tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         ...,\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.]]], device='cuda:0',\n",
            "       grad_fn=<UnsqueezeBackward0>)\n",
            "finalputput shape torch.Size([1, 1020, 1020])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "19\n",
            "cost tensor(369159.5000, device='cuda:0', grad_fn=<SoftMarginLossBackward0>)\n",
            "(3, 1020, 1020)\n",
            "raw_output1 max tensor(1.1478e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output1 shape torch.Size([1, 21, 1020, 1020])\n",
            "raw_output21 max tensor(1.1478e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output22 max tensor(-1.6600e+10, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output2 shape torch.Size([21, 1020, 1020])\n",
            "softmax_output max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[0] min tensor(1., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] shape torch.Size([1020, 1020])\n",
            "softmax_output[1] max tensor(0., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[1] min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[1] shape torch.Size([1020, 1020])\n",
            "finaloutput tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         ...,\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.]]], device='cuda:0',\n",
            "       grad_fn=<UnsqueezeBackward0>)\n",
            "finalputput shape torch.Size([1, 1020, 1020])\n",
            "raw_output1 max tensor(1.5729e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output1 shape torch.Size([1, 21, 1020, 1020])\n",
            "raw_output21 max tensor(1.5729e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output22 max tensor(-3.5278e+10, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output2 shape torch.Size([21, 1020, 1020])\n",
            "softmax_output max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[0] min tensor(1., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] shape torch.Size([1020, 1020])\n",
            "softmax_output[1] max tensor(0., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[1] min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[1] shape torch.Size([1020, 1020])\n",
            "finaloutput tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         ...,\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.]]], device='cuda:0',\n",
            "       grad_fn=<UnsqueezeBackward0>)\n",
            "finalputput shape torch.Size([1, 1020, 1020])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "21\n",
            "cost tensor(353707.5000, device='cuda:0', grad_fn=<SoftMarginLossBackward0>)\n",
            "(3, 1020, 1020)\n",
            "raw_output1 max tensor(1.8504e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output1 shape torch.Size([1, 21, 1020, 1020])\n",
            "raw_output21 max tensor(1.8504e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output22 max tensor(-3.2824e+10, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output2 shape torch.Size([21, 1020, 1020])\n",
            "softmax_output max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[0] min tensor(1., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] shape torch.Size([1020, 1020])\n",
            "softmax_output[1] max tensor(0., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[1] min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[1] shape torch.Size([1020, 1020])\n",
            "finaloutput tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         ...,\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.]]], device='cuda:0',\n",
            "       grad_fn=<UnsqueezeBackward0>)\n",
            "finalputput shape torch.Size([1, 1020, 1020])\n",
            "raw_output1 max tensor(2.3828e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output1 shape torch.Size([1, 21, 1020, 1020])\n",
            "raw_output21 max tensor(2.3828e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output22 max tensor(-3.0953e+10, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output2 shape torch.Size([21, 1020, 1020])\n",
            "softmax_output max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[0] min tensor(1., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] shape torch.Size([1020, 1020])\n",
            "softmax_output[1] max tensor(0., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[1] min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[1] shape torch.Size([1020, 1020])\n",
            "finaloutput tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         ...,\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.]]], device='cuda:0',\n",
            "       grad_fn=<UnsqueezeBackward0>)\n",
            "finalputput shape torch.Size([1, 1020, 1020])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "23\n",
            "cost tensor(414801.5000, device='cuda:0', grad_fn=<SoftMarginLossBackward0>)\n",
            "(3, 1020, 1020)\n",
            "raw_output1 max tensor(2.4395e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output1 shape torch.Size([1, 21, 1020, 1020])\n",
            "raw_output21 max tensor(2.4395e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output22 max tensor(-3.4883e+10, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output2 shape torch.Size([21, 1020, 1020])\n",
            "softmax_output max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[0] min tensor(1., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] shape torch.Size([1020, 1020])\n",
            "softmax_output[1] max tensor(0., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[1] min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[1] shape torch.Size([1020, 1020])\n",
            "finaloutput tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         ...,\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.]]], device='cuda:0',\n",
            "       grad_fn=<UnsqueezeBackward0>)\n",
            "finalputput shape torch.Size([1, 1020, 1020])\n",
            "raw_output1 max tensor(2.4908e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output1 shape torch.Size([1, 21, 1020, 1020])\n",
            "raw_output21 max tensor(2.4908e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output22 max tensor(-4.4752e+10, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output2 shape torch.Size([21, 1020, 1020])\n",
            "softmax_output max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[0] min tensor(1., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] shape torch.Size([1020, 1020])\n",
            "softmax_output[1] max tensor(0., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[1] min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[1] shape torch.Size([1020, 1020])\n",
            "finaloutput tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         ...,\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.]]], device='cuda:0',\n",
            "       grad_fn=<UnsqueezeBackward0>)\n",
            "finalputput shape torch.Size([1, 1020, 1020])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "25\n",
            "cost tensor(349612.5000, device='cuda:0', grad_fn=<SoftMarginLossBackward0>)\n",
            "(3, 1020, 1020)\n",
            "raw_output1 max tensor(3.5546e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output1 shape torch.Size([1, 21, 1020, 1020])\n",
            "raw_output21 max tensor(3.5546e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output22 max tensor(-6.2727e+10, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output2 shape torch.Size([21, 1020, 1020])\n",
            "softmax_output max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[0] min tensor(1., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] shape torch.Size([1020, 1020])\n",
            "softmax_output[1] max tensor(0., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[1] min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[1] shape torch.Size([1020, 1020])\n",
            "finaloutput tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         ...,\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.]]], device='cuda:0',\n",
            "       grad_fn=<UnsqueezeBackward0>)\n",
            "finalputput shape torch.Size([1, 1020, 1020])\n",
            "raw_output1 max tensor(3.2867e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output1 shape torch.Size([1, 21, 1020, 1020])\n",
            "raw_output21 max tensor(3.2867e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output22 max tensor(-3.7741e+10, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output2 shape torch.Size([21, 1020, 1020])\n",
            "softmax_output max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[0] min tensor(1., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] shape torch.Size([1020, 1020])\n",
            "softmax_output[1] max tensor(0., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[1] min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[1] shape torch.Size([1020, 1020])\n",
            "finaloutput tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         ...,\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.]]], device='cuda:0',\n",
            "       grad_fn=<UnsqueezeBackward0>)\n",
            "finalputput shape torch.Size([1, 1020, 1020])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "27\n",
            "cost tensor(385547.5000, device='cuda:0', grad_fn=<SoftMarginLossBackward0>)\n",
            "(3, 1020, 1020)\n",
            "raw_output1 max tensor(4.5442e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output1 shape torch.Size([1, 21, 1020, 1020])\n",
            "raw_output21 max tensor(4.5442e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output22 max tensor(-4.9043e+10, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output2 shape torch.Size([21, 1020, 1020])\n",
            "softmax_output max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[0] min tensor(1., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] shape torch.Size([1020, 1020])\n",
            "softmax_output[1] max tensor(0., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[1] min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[1] shape torch.Size([1020, 1020])\n",
            "finaloutput tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         ...,\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.]]], device='cuda:0',\n",
            "       grad_fn=<UnsqueezeBackward0>)\n",
            "finalputput shape torch.Size([1, 1020, 1020])\n",
            "raw_output1 max tensor(5.5932e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output1 shape torch.Size([1, 21, 1020, 1020])\n",
            "raw_output21 max tensor(5.5932e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output22 max tensor(-5.6105e+10, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output2 shape torch.Size([21, 1020, 1020])\n",
            "softmax_output max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[0] min tensor(1., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] shape torch.Size([1020, 1020])\n",
            "softmax_output[1] max tensor(0., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[1] min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[1] shape torch.Size([1020, 1020])\n",
            "finaloutput tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         ...,\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.]]], device='cuda:0',\n",
            "       grad_fn=<UnsqueezeBackward0>)\n",
            "finalputput shape torch.Size([1, 1020, 1020])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "29\n",
            "cost tensor(367371.5000, device='cuda:0', grad_fn=<SoftMarginLossBackward0>)\n",
            "(3, 1020, 1020)\n",
            "raw_output1 max tensor(4.7791e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output1 shape torch.Size([1, 21, 1020, 1020])\n",
            "raw_output21 max tensor(4.7791e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output22 max tensor(-7.5747e+10, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output2 shape torch.Size([21, 1020, 1020])\n",
            "softmax_output max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[0] min tensor(1., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] shape torch.Size([1020, 1020])\n",
            "softmax_output[1] max tensor(0., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[1] min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[1] shape torch.Size([1020, 1020])\n",
            "finaloutput tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         ...,\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.]]], device='cuda:0',\n",
            "       grad_fn=<UnsqueezeBackward0>)\n",
            "finalputput shape torch.Size([1, 1020, 1020])\n",
            "raw_output1 max tensor(3.8543e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output1 shape torch.Size([1, 21, 1020, 1020])\n",
            "raw_output21 max tensor(3.8543e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output22 max tensor(-5.6678e+10, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output2 shape torch.Size([21, 1020, 1020])\n",
            "softmax_output max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[0] min tensor(1., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] shape torch.Size([1020, 1020])\n",
            "softmax_output[1] max tensor(0., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[1] min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[1] shape torch.Size([1020, 1020])\n",
            "finaloutput tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         ...,\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.]]], device='cuda:0',\n",
            "       grad_fn=<UnsqueezeBackward0>)\n",
            "finalputput shape torch.Size([1, 1020, 1020])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "31\n",
            "cost tensor(364935.5000, device='cuda:0', grad_fn=<SoftMarginLossBackward0>)\n",
            "(3, 1020, 1020)\n",
            "raw_output1 max tensor(5.4706e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output1 shape torch.Size([1, 21, 1020, 1020])\n",
            "raw_output21 max tensor(5.4706e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output22 max tensor(-6.6727e+10, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output2 shape torch.Size([21, 1020, 1020])\n",
            "softmax_output max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[0] min tensor(1., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] shape torch.Size([1020, 1020])\n",
            "softmax_output[1] max tensor(0., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[1] min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[1] shape torch.Size([1020, 1020])\n",
            "finaloutput tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         ...,\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.]]], device='cuda:0',\n",
            "       grad_fn=<UnsqueezeBackward0>)\n",
            "finalputput shape torch.Size([1, 1020, 1020])\n",
            "raw_output1 max tensor(4.2263e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output1 shape torch.Size([1, 21, 1020, 1020])\n",
            "raw_output21 max tensor(4.2263e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output22 max tensor(-7.7833e+10, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output2 shape torch.Size([21, 1020, 1020])\n",
            "softmax_output max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[0] min tensor(1., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] shape torch.Size([1020, 1020])\n",
            "softmax_output[1] max tensor(0., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[1] min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[1] shape torch.Size([1020, 1020])\n",
            "finaloutput tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         ...,\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.]]], device='cuda:0',\n",
            "       grad_fn=<UnsqueezeBackward0>)\n",
            "finalputput shape torch.Size([1, 1020, 1020])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "33\n",
            "cost tensor(366395.5000, device='cuda:0', grad_fn=<SoftMarginLossBackward0>)\n",
            "(3, 1020, 1020)\n",
            "raw_output1 max tensor(5.9742e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output1 shape torch.Size([1, 21, 1020, 1020])\n",
            "raw_output21 max tensor(5.9742e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output22 max tensor(-1.2152e+11, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output2 shape torch.Size([21, 1020, 1020])\n",
            "softmax_output max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[0] min tensor(1., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] shape torch.Size([1020, 1020])\n",
            "softmax_output[1] max tensor(0., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[1] min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[1] shape torch.Size([1020, 1020])\n",
            "finaloutput tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         ...,\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.]]], device='cuda:0',\n",
            "       grad_fn=<UnsqueezeBackward0>)\n",
            "finalputput shape torch.Size([1, 1020, 1020])\n",
            "raw_output1 max tensor(5.8435e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output1 shape torch.Size([1, 21, 1020, 1020])\n",
            "raw_output21 max tensor(5.8435e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output22 max tensor(-8.9311e+10, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output2 shape torch.Size([21, 1020, 1020])\n",
            "softmax_output max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[0] min tensor(1., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] shape torch.Size([1020, 1020])\n",
            "softmax_output[1] max tensor(0., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[1] min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[1] shape torch.Size([1020, 1020])\n",
            "finaloutput tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         ...,\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.]]], device='cuda:0',\n",
            "       grad_fn=<UnsqueezeBackward0>)\n",
            "finalputput shape torch.Size([1, 1020, 1020])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "35\n",
            "cost tensor(388160.5000, device='cuda:0', grad_fn=<SoftMarginLossBackward0>)\n",
            "(3, 1020, 1020)\n",
            "raw_output1 max tensor(9.3404e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output1 shape torch.Size([1, 21, 1020, 1020])\n",
            "raw_output21 max tensor(9.3404e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output22 max tensor(-9.4302e+10, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output2 shape torch.Size([21, 1020, 1020])\n",
            "softmax_output max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[0] min tensor(1., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] shape torch.Size([1020, 1020])\n",
            "softmax_output[1] max tensor(0., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[1] min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[1] shape torch.Size([1020, 1020])\n",
            "finaloutput tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         ...,\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.]]], device='cuda:0',\n",
            "       grad_fn=<UnsqueezeBackward0>)\n",
            "finalputput shape torch.Size([1, 1020, 1020])\n",
            "raw_output1 max tensor(6.0929e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output1 shape torch.Size([1, 21, 1020, 1020])\n",
            "raw_output21 max tensor(6.0929e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output22 max tensor(-1.4847e+11, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output2 shape torch.Size([21, 1020, 1020])\n",
            "softmax_output max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[0] min tensor(1., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] shape torch.Size([1020, 1020])\n",
            "softmax_output[1] max tensor(0., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[1] min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[1] shape torch.Size([1020, 1020])\n",
            "finaloutput tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         ...,\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.]]], device='cuda:0',\n",
            "       grad_fn=<UnsqueezeBackward0>)\n",
            "finalputput shape torch.Size([1, 1020, 1020])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "37\n",
            "cost tensor(412465.5000, device='cuda:0', grad_fn=<SoftMarginLossBackward0>)\n",
            "(3, 1020, 1020)\n",
            "raw_output1 max tensor(5.8762e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output1 shape torch.Size([1, 21, 1020, 1020])\n",
            "raw_output21 max tensor(5.8762e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output22 max tensor(-1.0176e+11, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output2 shape torch.Size([21, 1020, 1020])\n",
            "softmax_output max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[0] min tensor(1., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] shape torch.Size([1020, 1020])\n",
            "softmax_output[1] max tensor(0., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[1] min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[1] shape torch.Size([1020, 1020])\n",
            "finaloutput tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         ...,\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.]]], device='cuda:0',\n",
            "       grad_fn=<UnsqueezeBackward0>)\n",
            "finalputput shape torch.Size([1, 1020, 1020])\n",
            "raw_output1 max tensor(7.9199e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output1 shape torch.Size([1, 21, 1020, 1020])\n",
            "raw_output21 max tensor(7.9199e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output22 max tensor(-1.5441e+11, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output2 shape torch.Size([21, 1020, 1020])\n",
            "softmax_output max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[0] min tensor(1., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] shape torch.Size([1020, 1020])\n",
            "softmax_output[1] max tensor(0., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[1] min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[1] shape torch.Size([1020, 1020])\n",
            "finaloutput tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         ...,\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.]]], device='cuda:0',\n",
            "       grad_fn=<UnsqueezeBackward0>)\n",
            "finalputput shape torch.Size([1, 1020, 1020])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "39\n",
            "cost tensor(364421.5000, device='cuda:0', grad_fn=<SoftMarginLossBackward0>)\n",
            "(3, 1020, 1020)\n",
            "raw_output1 max tensor(6.6877e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output1 shape torch.Size([1, 21, 1020, 1020])\n",
            "raw_output21 max tensor(6.6877e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output22 max tensor(-1.3911e+11, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output2 shape torch.Size([21, 1020, 1020])\n",
            "softmax_output max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[0] min tensor(1., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] shape torch.Size([1020, 1020])\n",
            "softmax_output[1] max tensor(0., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[1] min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[1] shape torch.Size([1020, 1020])\n",
            "finaloutput tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         ...,\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.]]], device='cuda:0',\n",
            "       grad_fn=<UnsqueezeBackward0>)\n",
            "finalputput shape torch.Size([1, 1020, 1020])\n",
            "raw_output1 max tensor(7.8561e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output1 shape torch.Size([1, 21, 1020, 1020])\n",
            "raw_output21 max tensor(7.8561e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output22 max tensor(-1.1081e+11, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output2 shape torch.Size([21, 1020, 1020])\n",
            "softmax_output max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[0] min tensor(1., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] shape torch.Size([1020, 1020])\n",
            "softmax_output[1] max tensor(0., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[1] min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[1] shape torch.Size([1020, 1020])\n",
            "finaloutput tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         ...,\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.]]], device='cuda:0',\n",
            "       grad_fn=<UnsqueezeBackward0>)\n",
            "finalputput shape torch.Size([1, 1020, 1020])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "41\n",
            "cost tensor(385397.5000, device='cuda:0', grad_fn=<SoftMarginLossBackward0>)\n",
            "(3, 1020, 1020)\n",
            "raw_output1 max tensor(6.7532e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output1 shape torch.Size([1, 21, 1020, 1020])\n",
            "raw_output21 max tensor(6.7532e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output22 max tensor(-1.3546e+11, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output2 shape torch.Size([21, 1020, 1020])\n",
            "softmax_output max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[0] min tensor(1., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] shape torch.Size([1020, 1020])\n",
            "softmax_output[1] max tensor(0., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[1] min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[1] shape torch.Size([1020, 1020])\n",
            "finaloutput tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         ...,\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.]]], device='cuda:0',\n",
            "       grad_fn=<UnsqueezeBackward0>)\n",
            "finalputput shape torch.Size([1, 1020, 1020])\n",
            "raw_output1 max tensor(5.7976e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output1 shape torch.Size([1, 21, 1020, 1020])\n",
            "raw_output21 max tensor(5.7976e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output22 max tensor(-1.3285e+11, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output2 shape torch.Size([21, 1020, 1020])\n",
            "softmax_output max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[0] min tensor(1., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] shape torch.Size([1020, 1020])\n",
            "softmax_output[1] max tensor(0., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[1] min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[1] shape torch.Size([1020, 1020])\n",
            "finaloutput tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         ...,\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.]]], device='cuda:0',\n",
            "       grad_fn=<UnsqueezeBackward0>)\n",
            "finalputput shape torch.Size([1, 1020, 1020])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "43\n",
            "cost tensor(349182.5000, device='cuda:0', grad_fn=<SoftMarginLossBackward0>)\n",
            "(3, 1020, 1020)\n",
            "raw_output1 max tensor(6.5920e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output1 shape torch.Size([1, 21, 1020, 1020])\n",
            "raw_output21 max tensor(6.5920e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output22 max tensor(-1.5923e+11, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output2 shape torch.Size([21, 1020, 1020])\n",
            "softmax_output max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[0] min tensor(1., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] shape torch.Size([1020, 1020])\n",
            "softmax_output[1] max tensor(0., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[1] min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[1] shape torch.Size([1020, 1020])\n",
            "finaloutput tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         ...,\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.]]], device='cuda:0',\n",
            "       grad_fn=<UnsqueezeBackward0>)\n",
            "finalputput shape torch.Size([1, 1020, 1020])\n",
            "raw_output1 max tensor(7.7145e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output1 shape torch.Size([1, 21, 1020, 1020])\n",
            "raw_output21 max tensor(7.7145e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output22 max tensor(-1.5106e+11, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output2 shape torch.Size([21, 1020, 1020])\n",
            "softmax_output max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[0] min tensor(1., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] shape torch.Size([1020, 1020])\n",
            "softmax_output[1] max tensor(0., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[1] min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[1] shape torch.Size([1020, 1020])\n",
            "finaloutput tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         ...,\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.]]], device='cuda:0',\n",
            "       grad_fn=<UnsqueezeBackward0>)\n",
            "finalputput shape torch.Size([1, 1020, 1020])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "45\n",
            "cost tensor(380050.5000, device='cuda:0', grad_fn=<SoftMarginLossBackward0>)\n",
            "(3, 1020, 1020)\n",
            "raw_output1 max tensor(7.5786e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output1 shape torch.Size([1, 21, 1020, 1020])\n",
            "raw_output21 max tensor(7.5786e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output22 max tensor(-1.3521e+11, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output2 shape torch.Size([21, 1020, 1020])\n",
            "softmax_output max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[0] min tensor(1., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] shape torch.Size([1020, 1020])\n",
            "softmax_output[1] max tensor(0., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[1] min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[1] shape torch.Size([1020, 1020])\n",
            "finaloutput tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         ...,\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.]]], device='cuda:0',\n",
            "       grad_fn=<UnsqueezeBackward0>)\n",
            "finalputput shape torch.Size([1, 1020, 1020])\n",
            "raw_output1 max tensor(7.1259e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output1 shape torch.Size([1, 21, 1020, 1020])\n",
            "raw_output21 max tensor(7.1259e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output22 max tensor(-1.2814e+11, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output2 shape torch.Size([21, 1020, 1020])\n",
            "softmax_output max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[0] min tensor(1., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] shape torch.Size([1020, 1020])\n",
            "softmax_output[1] max tensor(0., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[1] min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[1] shape torch.Size([1020, 1020])\n",
            "finaloutput tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         ...,\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.]]], device='cuda:0',\n",
            "       grad_fn=<UnsqueezeBackward0>)\n",
            "finalputput shape torch.Size([1, 1020, 1020])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "47\n",
            "cost tensor(342435.5000, device='cuda:0', grad_fn=<SoftMarginLossBackward0>)\n",
            "(3, 1020, 1020)\n",
            "raw_output1 max tensor(9.1413e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output1 shape torch.Size([1, 21, 1020, 1020])\n",
            "raw_output21 max tensor(9.1413e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output22 max tensor(-1.3311e+11, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output2 shape torch.Size([21, 1020, 1020])\n",
            "softmax_output max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[0] min tensor(1., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] shape torch.Size([1020, 1020])\n",
            "softmax_output[1] max tensor(0., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[1] min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[1] shape torch.Size([1020, 1020])\n",
            "finaloutput tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         ...,\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.]]], device='cuda:0',\n",
            "       grad_fn=<UnsqueezeBackward0>)\n",
            "finalputput shape torch.Size([1, 1020, 1020])\n",
            "raw_output1 max tensor(7.8892e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output1 shape torch.Size([1, 21, 1020, 1020])\n",
            "raw_output21 max tensor(7.8892e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output22 max tensor(-1.4446e+11, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output2 shape torch.Size([21, 1020, 1020])\n",
            "softmax_output max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[0] min tensor(1., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] shape torch.Size([1020, 1020])\n",
            "softmax_output[1] max tensor(0., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[1] min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[1] shape torch.Size([1020, 1020])\n",
            "finaloutput tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         ...,\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.]]], device='cuda:0',\n",
            "       grad_fn=<UnsqueezeBackward0>)\n",
            "finalputput shape torch.Size([1, 1020, 1020])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "49\n",
            "cost tensor(367086.5000, device='cuda:0', grad_fn=<SoftMarginLossBackward0>)\n",
            "(3, 1020, 1020)\n",
            "raw_output1 max tensor(7.4741e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output1 shape torch.Size([1, 21, 1020, 1020])\n",
            "raw_output21 max tensor(7.4741e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output22 max tensor(-5.9176e+10, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output2 shape torch.Size([21, 1020, 1020])\n",
            "softmax_output max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[0] min tensor(1., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] shape torch.Size([1020, 1020])\n",
            "softmax_output[1] max tensor(0., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[1] min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[1] shape torch.Size([1020, 1020])\n",
            "finaloutput tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         ...,\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.]]], device='cuda:0',\n",
            "       grad_fn=<UnsqueezeBackward0>)\n",
            "finalputput shape torch.Size([1, 1020, 1020])\n",
            "raw_output1 max tensor(7.8204e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output1 shape torch.Size([1, 21, 1020, 1020])\n",
            "raw_output21 max tensor(7.8204e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output22 max tensor(-1.6353e+11, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output2 shape torch.Size([21, 1020, 1020])\n",
            "softmax_output max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[0] min tensor(1., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] shape torch.Size([1020, 1020])\n",
            "softmax_output[1] max tensor(0., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[1] min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[1] shape torch.Size([1020, 1020])\n",
            "finaloutput tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         ...,\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.]]], device='cuda:0',\n",
            "       grad_fn=<UnsqueezeBackward0>)\n",
            "finalputput shape torch.Size([1, 1020, 1020])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "51\n",
            "cost tensor(405763.5000, device='cuda:0', grad_fn=<SoftMarginLossBackward0>)\n",
            "(3, 1020, 1020)\n",
            "raw_output1 max tensor(6.5273e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output1 shape torch.Size([1, 21, 1020, 1020])\n",
            "raw_output21 max tensor(6.5273e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output22 max tensor(-1.5262e+11, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output2 shape torch.Size([21, 1020, 1020])\n",
            "softmax_output max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[0] min tensor(1., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] shape torch.Size([1020, 1020])\n",
            "softmax_output[1] max tensor(0., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[1] min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[1] shape torch.Size([1020, 1020])\n",
            "finaloutput tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         ...,\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.]]], device='cuda:0',\n",
            "       grad_fn=<UnsqueezeBackward0>)\n",
            "finalputput shape torch.Size([1, 1020, 1020])\n",
            "raw_output1 max tensor(8.8755e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output1 shape torch.Size([1, 21, 1020, 1020])\n",
            "raw_output21 max tensor(8.8755e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output22 max tensor(-1.0316e+11, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output2 shape torch.Size([21, 1020, 1020])\n",
            "softmax_output max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[0] min tensor(1., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] shape torch.Size([1020, 1020])\n",
            "softmax_output[1] max tensor(0., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[1] min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[1] shape torch.Size([1020, 1020])\n",
            "finaloutput tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         ...,\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.]]], device='cuda:0',\n",
            "       grad_fn=<UnsqueezeBackward0>)\n",
            "finalputput shape torch.Size([1, 1020, 1020])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "53\n",
            "cost tensor(341556.5000, device='cuda:0', grad_fn=<SoftMarginLossBackward0>)\n",
            "(3, 1020, 1020)\n",
            "raw_output1 max tensor(9.0488e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output1 shape torch.Size([1, 21, 1020, 1020])\n",
            "raw_output21 max tensor(9.0488e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output22 max tensor(-1.6941e+11, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output2 shape torch.Size([21, 1020, 1020])\n",
            "softmax_output max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[0] min tensor(1., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] shape torch.Size([1020, 1020])\n",
            "softmax_output[1] max tensor(0., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[1] min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[1] shape torch.Size([1020, 1020])\n",
            "finaloutput tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         ...,\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.]]], device='cuda:0',\n",
            "       grad_fn=<UnsqueezeBackward0>)\n",
            "finalputput shape torch.Size([1, 1020, 1020])\n",
            "raw_output1 max tensor(1.0337e+13, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output1 shape torch.Size([1, 21, 1020, 1020])\n",
            "raw_output21 max tensor(1.0337e+13, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output22 max tensor(-9.5988e+10, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output2 shape torch.Size([21, 1020, 1020])\n",
            "softmax_output max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[0] min tensor(1., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] shape torch.Size([1020, 1020])\n",
            "softmax_output[1] max tensor(0., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[1] min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[1] shape torch.Size([1020, 1020])\n",
            "finaloutput tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         ...,\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.]]], device='cuda:0',\n",
            "       grad_fn=<UnsqueezeBackward0>)\n",
            "finalputput shape torch.Size([1, 1020, 1020])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "55\n",
            "cost tensor(360535.5000, device='cuda:0', grad_fn=<SoftMarginLossBackward0>)\n",
            "(3, 1020, 1020)\n",
            "raw_output1 max tensor(7.9409e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output1 shape torch.Size([1, 21, 1020, 1020])\n",
            "raw_output21 max tensor(7.9409e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output22 max tensor(-1.3318e+11, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output2 shape torch.Size([21, 1020, 1020])\n",
            "softmax_output max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[0] min tensor(1., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] shape torch.Size([1020, 1020])\n",
            "softmax_output[1] max tensor(0., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[1] min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[1] shape torch.Size([1020, 1020])\n",
            "finaloutput tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         ...,\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.]]], device='cuda:0',\n",
            "       grad_fn=<UnsqueezeBackward0>)\n",
            "finalputput shape torch.Size([1, 1020, 1020])\n",
            "raw_output1 max tensor(7.2209e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output1 shape torch.Size([1, 21, 1020, 1020])\n",
            "raw_output21 max tensor(7.2209e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output22 max tensor(-1.4606e+11, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output2 shape torch.Size([21, 1020, 1020])\n",
            "softmax_output max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[0] min tensor(1., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] shape torch.Size([1020, 1020])\n",
            "softmax_output[1] max tensor(0., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[1] min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[1] shape torch.Size([1020, 1020])\n",
            "finaloutput tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         ...,\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.]]], device='cuda:0',\n",
            "       grad_fn=<UnsqueezeBackward0>)\n",
            "finalputput shape torch.Size([1, 1020, 1020])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "57\n",
            "cost tensor(367819.5000, device='cuda:0', grad_fn=<SoftMarginLossBackward0>)\n",
            "(3, 1020, 1020)\n",
            "raw_output1 max tensor(8.9260e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output1 shape torch.Size([1, 21, 1020, 1020])\n",
            "raw_output21 max tensor(8.9260e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output22 max tensor(-2.1474e+11, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output2 shape torch.Size([21, 1020, 1020])\n",
            "softmax_output max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[0] min tensor(1., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] shape torch.Size([1020, 1020])\n",
            "softmax_output[1] max tensor(0., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[1] min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[1] shape torch.Size([1020, 1020])\n",
            "finaloutput tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         ...,\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.]]], device='cuda:0',\n",
            "       grad_fn=<UnsqueezeBackward0>)\n",
            "finalputput shape torch.Size([1, 1020, 1020])\n",
            "raw_output1 max tensor(8.2543e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output1 shape torch.Size([1, 21, 1020, 1020])\n",
            "raw_output21 max tensor(8.2543e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output22 max tensor(-1.5718e+11, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output2 shape torch.Size([21, 1020, 1020])\n",
            "softmax_output max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[0] min tensor(1., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] shape torch.Size([1020, 1020])\n",
            "softmax_output[1] max tensor(0., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[1] min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[1] shape torch.Size([1020, 1020])\n",
            "finaloutput tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         ...,\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.]]], device='cuda:0',\n",
            "       grad_fn=<UnsqueezeBackward0>)\n",
            "finalputput shape torch.Size([1, 1020, 1020])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "59\n",
            "cost tensor(380074.5000, device='cuda:0', grad_fn=<SoftMarginLossBackward0>)\n",
            "(3, 1020, 1020)\n",
            "raw_output1 max tensor(8.0453e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output1 shape torch.Size([1, 21, 1020, 1020])\n",
            "raw_output21 max tensor(8.0453e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output22 max tensor(-1.9481e+11, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output2 shape torch.Size([21, 1020, 1020])\n",
            "softmax_output max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[0] min tensor(1., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] shape torch.Size([1020, 1020])\n",
            "softmax_output[1] max tensor(0., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[1] min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[1] shape torch.Size([1020, 1020])\n",
            "finaloutput tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         ...,\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.]]], device='cuda:0',\n",
            "       grad_fn=<UnsqueezeBackward0>)\n",
            "finalputput shape torch.Size([1, 1020, 1020])\n",
            "raw_output1 max tensor(8.6966e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output1 shape torch.Size([1, 21, 1020, 1020])\n",
            "raw_output21 max tensor(8.6966e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output22 max tensor(-2.1217e+11, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output2 shape torch.Size([21, 1020, 1020])\n",
            "softmax_output max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[0] min tensor(1., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] shape torch.Size([1020, 1020])\n",
            "softmax_output[1] max tensor(0., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[1] min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[1] shape torch.Size([1020, 1020])\n",
            "finaloutput tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         ...,\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.]]], device='cuda:0',\n",
            "       grad_fn=<UnsqueezeBackward0>)\n",
            "finalputput shape torch.Size([1, 1020, 1020])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "61\n",
            "cost tensor(414751.5000, device='cuda:0', grad_fn=<SoftMarginLossBackward0>)\n",
            "(3, 1020, 1020)\n",
            "raw_output1 max tensor(9.1915e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output1 shape torch.Size([1, 21, 1020, 1020])\n",
            "raw_output21 max tensor(9.1915e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output22 max tensor(-1.1192e+11, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output2 shape torch.Size([21, 1020, 1020])\n",
            "softmax_output max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[0] min tensor(1., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] shape torch.Size([1020, 1020])\n",
            "softmax_output[1] max tensor(0., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[1] min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[1] shape torch.Size([1020, 1020])\n",
            "finaloutput tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         ...,\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.]]], device='cuda:0',\n",
            "       grad_fn=<UnsqueezeBackward0>)\n",
            "finalputput shape torch.Size([1, 1020, 1020])\n",
            "raw_output1 max tensor(1.0607e+13, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output1 shape torch.Size([1, 21, 1020, 1020])\n",
            "raw_output21 max tensor(1.0607e+13, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output22 max tensor(-2.0480e+11, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output2 shape torch.Size([21, 1020, 1020])\n",
            "softmax_output max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[0] min tensor(1., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] shape torch.Size([1020, 1020])\n",
            "softmax_output[1] max tensor(0., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[1] min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[1] shape torch.Size([1020, 1020])\n",
            "finaloutput tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         ...,\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.]]], device='cuda:0',\n",
            "       grad_fn=<UnsqueezeBackward0>)\n",
            "finalputput shape torch.Size([1, 1020, 1020])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "63\n",
            "cost tensor(391886.5000, device='cuda:0', grad_fn=<SoftMarginLossBackward0>)\n",
            "(3, 1020, 1020)\n",
            "raw_output1 max tensor(9.3105e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output1 shape torch.Size([1, 21, 1020, 1020])\n",
            "raw_output21 max tensor(9.3105e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output22 max tensor(-1.8221e+11, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output2 shape torch.Size([21, 1020, 1020])\n",
            "softmax_output max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[0] min tensor(1., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] shape torch.Size([1020, 1020])\n",
            "softmax_output[1] max tensor(0., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[1] min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[1] shape torch.Size([1020, 1020])\n",
            "finaloutput tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         ...,\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.]]], device='cuda:0',\n",
            "       grad_fn=<UnsqueezeBackward0>)\n",
            "finalputput shape torch.Size([1, 1020, 1020])\n",
            "raw_output1 max tensor(1.0199e+13, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output1 shape torch.Size([1, 21, 1020, 1020])\n",
            "raw_output21 max tensor(1.0199e+13, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output22 max tensor(-1.6425e+11, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output2 shape torch.Size([21, 1020, 1020])\n",
            "softmax_output max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[0] min tensor(1., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] shape torch.Size([1020, 1020])\n",
            "softmax_output[1] max tensor(0., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[1] min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[1] shape torch.Size([1020, 1020])\n",
            "finaloutput tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         ...,\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.]]], device='cuda:0',\n",
            "       grad_fn=<UnsqueezeBackward0>)\n",
            "finalputput shape torch.Size([1, 1020, 1020])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "65\n",
            "cost tensor(358313.5000, device='cuda:0', grad_fn=<SoftMarginLossBackward0>)\n",
            "(3, 1020, 1020)\n",
            "raw_output1 max tensor(6.9302e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output1 shape torch.Size([1, 21, 1020, 1020])\n",
            "raw_output21 max tensor(6.9302e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output22 max tensor(-1.1118e+11, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output2 shape torch.Size([21, 1020, 1020])\n",
            "softmax_output max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[0] min tensor(1., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] shape torch.Size([1020, 1020])\n",
            "softmax_output[1] max tensor(0., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[1] min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[1] shape torch.Size([1020, 1020])\n",
            "finaloutput tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         ...,\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.]]], device='cuda:0',\n",
            "       grad_fn=<UnsqueezeBackward0>)\n",
            "finalputput shape torch.Size([1, 1020, 1020])\n",
            "raw_output1 max tensor(1.1269e+13, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output1 shape torch.Size([1, 21, 1020, 1020])\n",
            "raw_output21 max tensor(1.1269e+13, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output22 max tensor(-1.6452e+11, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output2 shape torch.Size([21, 1020, 1020])\n",
            "softmax_output max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[0] min tensor(1., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] shape torch.Size([1020, 1020])\n",
            "softmax_output[1] max tensor(0., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[1] min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[1] shape torch.Size([1020, 1020])\n",
            "finaloutput tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         ...,\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.]]], device='cuda:0',\n",
            "       grad_fn=<UnsqueezeBackward0>)\n",
            "finalputput shape torch.Size([1, 1020, 1020])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "67\n",
            "cost tensor(368099.5000, device='cuda:0', grad_fn=<SoftMarginLossBackward0>)\n",
            "(3, 1020, 1020)\n",
            "raw_output1 max tensor(1.2672e+13, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output1 shape torch.Size([1, 21, 1020, 1020])\n",
            "raw_output21 max tensor(1.2672e+13, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output22 max tensor(-1.1243e+11, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output2 shape torch.Size([21, 1020, 1020])\n",
            "softmax_output max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[0] min tensor(1., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] shape torch.Size([1020, 1020])\n",
            "softmax_output[1] max tensor(0., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[1] min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[1] shape torch.Size([1020, 1020])\n",
            "finaloutput tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         ...,\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.]]], device='cuda:0',\n",
            "       grad_fn=<UnsqueezeBackward0>)\n",
            "finalputput shape torch.Size([1, 1020, 1020])\n",
            "raw_output1 max tensor(9.7335e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output1 shape torch.Size([1, 21, 1020, 1020])\n",
            "raw_output21 max tensor(9.7335e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output22 max tensor(-1.1367e+11, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output2 shape torch.Size([21, 1020, 1020])\n",
            "softmax_output max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[0] min tensor(1., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] shape torch.Size([1020, 1020])\n",
            "softmax_output[1] max tensor(0., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[1] min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[1] shape torch.Size([1020, 1020])\n",
            "finaloutput tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         ...,\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.]]], device='cuda:0',\n",
            "       grad_fn=<UnsqueezeBackward0>)\n",
            "finalputput shape torch.Size([1, 1020, 1020])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "69\n",
            "cost tensor(357189.5000, device='cuda:0', grad_fn=<SoftMarginLossBackward0>)\n",
            "(3, 1020, 1020)\n",
            "raw_output1 max tensor(1.0392e+13, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output1 shape torch.Size([1, 21, 1020, 1020])\n",
            "raw_output21 max tensor(1.0392e+13, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output22 max tensor(-1.8497e+11, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output2 shape torch.Size([21, 1020, 1020])\n",
            "softmax_output max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[0] min tensor(1., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] shape torch.Size([1020, 1020])\n",
            "softmax_output[1] max tensor(0., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[1] min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[1] shape torch.Size([1020, 1020])\n",
            "finaloutput tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         ...,\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.]]], device='cuda:0',\n",
            "       grad_fn=<UnsqueezeBackward0>)\n",
            "finalputput shape torch.Size([1, 1020, 1020])\n",
            "raw_output1 max tensor(7.5706e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output1 shape torch.Size([1, 21, 1020, 1020])\n",
            "raw_output21 max tensor(7.5706e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output22 max tensor(-1.6437e+11, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output2 shape torch.Size([21, 1020, 1020])\n",
            "softmax_output max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[0] min tensor(1., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] shape torch.Size([1020, 1020])\n",
            "softmax_output[1] max tensor(0., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[1] min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[1] shape torch.Size([1020, 1020])\n",
            "finaloutput tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         ...,\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.]]], device='cuda:0',\n",
            "       grad_fn=<UnsqueezeBackward0>)\n",
            "finalputput shape torch.Size([1, 1020, 1020])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "71\n",
            "cost tensor(349464.5000, device='cuda:0', grad_fn=<SoftMarginLossBackward0>)\n",
            "(3, 1020, 1020)\n",
            "raw_output1 max tensor(6.6361e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output1 shape torch.Size([1, 21, 1020, 1020])\n",
            "raw_output21 max tensor(6.6361e+12, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output22 max tensor(-2.0651e+11, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "raw_output2 shape torch.Size([21, 1020, 1020])\n",
            "softmax_output max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] max tensor(1., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[0] min tensor(1., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[0] shape torch.Size([1020, 1020])\n",
            "softmax_output[1] max tensor(0., device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "softmax_output[1] min tensor(0., device='cuda:0', grad_fn=<MinBackward1>)\n",
            "softmax_output[1] shape torch.Size([1020, 1020])\n",
            "finaloutput tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         ...,\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "         [-1., -1., -1.,  ..., -1., -1., -1.]]], device='cuda:0',\n",
            "       grad_fn=<UnsqueezeBackward0>)\n",
            "finalputput shape torch.Size([1, 1020, 1020])\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-11-bbd62a4d6002>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# study.optimize(objective, n_trials=5)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mobjective\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m<ipython-input-10-791eb3d4f5ab>\u001b[0m in \u001b[0;36mobjective\u001b[1;34m(trial, model)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m             \u001b[1;31m# print statistics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m             \u001b[0mepoch_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m             \u001b[0mmini_epoch_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m             \u001b[1;31m# if i % 1000 == 999:    # print every 1000 mini-batches\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# study = optuna.create_study(direction='minimize', study_name=experiment_name)\n",
        "# study.optimize(objective, n_trials=5)\n",
        "\n",
        "objective(None, model)\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f47d3d7",
      "metadata": {},
      "outputs": [],
      "source": [
        "    pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
        "    complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
        "\n",
        "    #print(\"Study statistics: \")\n",
        "    #print(\"  Number of finished trials: \", len(study.trials))\n",
        "    #print(\"  Number of pruned trials: \", len(pruned_trials))\n",
        "    #print(\"  Number of complete trials: \", len(complete_trials))\n",
        "\n",
        "    #print(\"Best trial:\")\n",
        "    trial = study.best_trial\n",
        "\n",
        "    #print(\"  Value: \", trial.value)\n",
        "\n",
        "    #print(\"  Params: \")\n",
        "    for key, value in trial.params.items():\n",
        "        #print(\"    {}: {}\".format(key, value))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22e90282",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64f2f4b5",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c3be34c",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa9198b1",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a8ebdd9",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e79758fc",
      "metadata": {},
      "outputs": [],
      "source": [
        "def test(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    #print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8caa42c6",
      "metadata": {},
      "source": [
        "Show a test of the newly trained (fine tuned) model below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33dad314",
      "metadata": {},
      "outputs": [],
      "source": [
        "model.eval()\n",
        "\n",
        "# Display image and label.\n",
        "test_features, test_labels = next(iter(test_dataloader))\n",
        "#print(f\"Feature batch shape: {test_features.size()}\")\n",
        "#print(f\"Labels batch shape: {test_labels.size()}\")\n",
        "input_image = test_features[0].squeeze()\n",
        "input_image = np.moveaxis(input_image.numpy(), 0, -1)\n",
        "label = test_labels[0].reshape((img_width, img_height))\n",
        "\n",
        "plt.imshow(input_image, cmap=\"gray\")\n",
        "plt.show()\n",
        "plt.imshow(label, cmap=\"gray\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2f76b07",
      "metadata": {},
      "outputs": [],
      "source": [
        "# input_image = Image.open(filename)\n",
        "input_image2 = cv.cvtColor(input_image, cv.COLOR_BGR2RGB)\n",
        "input_image2 = Image.fromarray(np.uint8(input_image2))\n",
        "input_image2 = input_image2.convert(\"RGB\")\n",
        "\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "input_tensor = preprocess(input_image)\n",
        "input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
        "\n",
        "# move the input and model to GPU for speed if available\n",
        "if torch.cuda.is_available():\n",
        "    input_batch = input_batch.to('cuda')\n",
        "    model.to('cuda')\n",
        "\n",
        "with torch.no_grad():\n",
        "    output = model(input_batch)['out'][0] #zero refers to the batch number?\n",
        "output_predictions = output.argmax(0)\n",
        "#print(output_predictions)\n",
        "#print(output_predictions.shape)\n",
        "#print(output)\n",
        "#print(output.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d9d37c0",
      "metadata": {},
      "outputs": [],
      "source": [
        "test(test_dataloader, model, criterion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee44acb2",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "pytorch_vision_fcn_resnet101.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
