{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "intensive-butter",
      "metadata": {
        "id": "intensive-butter"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in C:\\Users\\maxan/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n",
            "ipykernel_launcher:26: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "ipykernel_launcher:30: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "FCN(\n",
              "  (backbone): IntermediateLayerGetter(\n",
              "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (layer1): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer2): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer3): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (4): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (5): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer4): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (classifier): FCNHead(\n",
              "    (0): Conv2d(2048, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): Dropout(p=0.1, inplace=False)\n",
              "    (4): Conv2d(512, 2, kernel_size=(1, 1), stride=(1, 1))\n",
              "  )\n",
              "  (aux_classifier): FCNHead(\n",
              "    (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): Dropout(p=0.1, inplace=False)\n",
              "    (4): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "model = torch.hub.load('pytorch/vision:v0.10.0', 'fcn_resnet50', pretrained=True)\n",
        "# or\n",
        "# model = torch.hub.load('pytorch/vision:v0.10.0', 'fcn_resnet101', pretrained=True)\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from generate_training_validation_data import CustomImageDataset\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "train_data_dir = 'D:/MemeMachine_ProjectData/dataset/training'\n",
        "validation_data_dir = 'D:/MemeMachine_ProjectData/dataset/validation'\n",
        "img_width, img_height, n_channels = 128, 128, 3 #TODO change dimensions to be wider, to better support text\n",
        "\n",
        "epochs = 1 #50 TODO\n",
        "batch_size = 1\n",
        "classes = ['nothing', 'text']\n",
        "# classes = ['text']\n",
        "\n",
        "\n",
        "#change the number of classes in the final step of the classifier\n",
        "# print(model.classifier[4])\n",
        "model.classifier[4] = torch.nn.Conv2d(512, len(classes), kernel_size=(1,1), stride = (1,1))\n",
        "torch.nn.init.xavier_uniform(model.classifier[4].weight)\n",
        "\n",
        "# print(model.aux_classifier[4])\n",
        "model.aux_classifier[4] = torch.nn.Conv2d(256, len(classes), kernel_size=(1,1), stride = (1,1))\n",
        "torch.nn.init.xavier_uniform(model.aux_classifier[4].weight)\n",
        "\n",
        "model.eval()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "0c9113ab",
      "metadata": {},
      "outputs": [],
      "source": [
        "experiment_name = \"increase_text_thickness_to_3_test10\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "066cdf42",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "env: CUDA_LAUNCH_BLOCKING=1\n"
          ]
        }
      ],
      "source": [
        "torch.backends.cudnn.benchmark = True\n",
        "%env CUDA_LAUNCH_BLOCKING=1\n",
        "\n",
        "import torch\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.benchmark = True\n",
        "torch.backends.cudnn.deterministic = False\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "data = torch.randn([1, 512, 16, 16], dtype=torch.float, device='cuda', requires_grad=True)\n",
        "net = torch.nn.Conv2d(512, 1, kernel_size=[1, 1], padding=[0, 0], stride=[1, 1], dilation=[1, 1], groups=1)\n",
        "net = net.cuda().float()\n",
        "out = net(data)\n",
        "out.backward(torch.randn_like(out))\n",
        "torch.cuda.synchronize()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "accredited-belize",
      "metadata": {
        "id": "accredited-belize"
      },
      "source": [
        "All pre-trained models expect input images normalized in the same way,\n",
        "i.e. mini-batches of 3-channel RGB images of shape `(N, 3, H, W)`, where `N` is the number of images, `H` and `W` are expected to be at least `224` pixels.\n",
        "The images have to be loaded in to a range of `[0, 1]` and then normalized using `mean = [0.485, 0.456, 0.406]`\n",
        "and `std = [0.229, 0.224, 0.225]`.\n",
        "\n",
        "The model returns an `OrderedDict` with two Tensors that are of the same height and width as the input Tensor, but with 21 classes.\n",
        "`output['out']` contains the semantic masks, and `output['aux']` contains the auxillary loss values per-pixel. In inference mode, `output['aux']` is not useful.\n",
        "So, `output['out']` is of shape `(N, 21, H, W)`. More documentation can be found [here](https://pytorch.org/vision/stable/models.html#object-detection-instance-segmentation-and-person-keypoint-detection)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "thirty-crown",
      "metadata": {
        "id": "thirty-crown"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature batch shape: torch.Size([1, 3, 128, 128])\n",
            "Labels batch shape: torch.Size([1, 16384])\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Select an image from the dataset\n",
        "\n",
        "#TODO change image_with_text_functions.generate_text_on_image_and_pixel_mask_from_path to place the text properly\n",
        "train_dataset = CustomImageDataset(train_data_dir, img_width, img_height)\n",
        "test_dataset = CustomImageDataset(validation_data_dir, img_width, img_height)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=8, pin_memory=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Display image and label.\n",
        "train_features, train_labels = next(iter(train_dataloader))\n",
        "print(f\"Feature batch shape: {train_features.size()}\")\n",
        "print(f\"Labels batch shape: {train_labels.size()}\")\n",
        "input_image = train_features[0].squeeze()\n",
        "input_image = np.moveaxis(input_image.numpy(), 0, -1)\n",
        "label = train_labels[0].reshape((img_width, img_height))\n",
        "\n",
        "# print('train_labels[0]', train_labels[0].max())\n",
        "# print('label', label.max())\n",
        "# label = label*256\n",
        "# label = label.long()\n",
        "# print('label', label.max())\n",
        "# print(train_labels[0])\n",
        "# print(label.shape)\n",
        "\n",
        "\n",
        "plt.imshow(input_image, cmap=\"gray\")\n",
        "plt.show()\n",
        "plt.imshow(label, cmap=\"gray\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "running-blogger",
      "metadata": {
        "id": "running-blogger"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 3, 128, 128])\n"
          ]
        }
      ],
      "source": [
        "# sample execution (requires torchvision)\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "import cv2 as cv\n",
        "# input_image = Image.open(filename)\n",
        "input_image2 = cv.cvtColor(input_image, cv.COLOR_BGR2RGB)\n",
        "input_image2 = Image.fromarray(np.uint8(input_image2))\n",
        "input_image2 = input_image2.convert(\"RGB\")\n",
        "\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "input_tensor = preprocess(input_image)\n",
        "input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
        "\n",
        "# move the input and model to GPU for speed if available\n",
        "if torch.cuda.is_available():\n",
        "    input_batch = input_batch.to('cuda')\n",
        "    model.to('cuda')\n",
        "print(input_batch.shape)\n",
        "with torch.no_grad():\n",
        "    output = model(input_batch)['out'][0] #zero refers to the batch number?\n",
        "output_predictions = output.argmax(0)\n",
        "# print(output_predictions)\n",
        "# print(output_predictions.shape)\n",
        "# print(output)\n",
        "# print(output.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lesbian-vietnamese",
      "metadata": {
        "id": "lesbian-vietnamese"
      },
      "source": [
        "The output here is of shape `(21, H, W)`, and at each location, there are unnormalized probabilities corresponding to the prediction of each class.\n",
        "To get the maximum prediction of each class, and then use it for a downstream task, you can do `output_predictions = output.argmax(0)`.\n",
        "\n",
        "Here's a small snippet that plots the predictions, with each color being assigned to each class (see the visualized image on the left)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "starting-delhi",
      "metadata": {
        "id": "starting-delhi"
      },
      "source": [
        "### Model Description\n",
        "\n",
        "FCN-ResNet is constructed by a Fully-Convolutional Network model, using a ResNet-50 or a ResNet-101 backbone.\n",
        "The pre-trained models have been trained on a subset of COCO train2017, on the 20 categories that are present in the Pascal VOC dataset.\n",
        "\n",
        "Their accuracies of the pre-trained models evaluated on COCO val2017 dataset are listed below.\n",
        "\n",
        "| Model structure |   Mean IOU  | Global Pixelwise Accuracy |\n",
        "| --------------- | ----------- | --------------------------|\n",
        "|  fcn_resnet50   |   60.5      |   91.4                    |\n",
        "|  fcn_resnet101  |   63.7      |   91.9                    |\n",
        "\n",
        "### Resources\n",
        "\n",
        " - [Fully Convolutional Networks for Semantic Segmentation](https://arxiv.org/abs/1605.06211)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "193ad198",
      "metadata": {},
      "outputs": [],
      "source": [
        "from collections import namedtuple\n",
        "from typing import Any\n",
        "import torch\n",
        "\n",
        "\n",
        "# pylint: disable = abstract-method\n",
        "class ModelWrapper(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Wrapper class for model with dict/list rvalues.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model: torch.nn.Module) -> None:\n",
        "        \"\"\"\n",
        "        Init call.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "\n",
        "    def forward(self, input_x: torch.Tensor) -> Any:\n",
        "        \"\"\"\n",
        "        Wrap forward call.\n",
        "        \"\"\"\n",
        "        data = self.model(input_x)\n",
        "\n",
        "        if isinstance(data, dict):\n",
        "            data_named_tuple = namedtuple(\"ModelEndpoints\", sorted(data.keys()))  # type: ignore\n",
        "            data = data_named_tuple(**data)  # type: ignore\n",
        "\n",
        "        elif isinstance(data, list):\n",
        "            data = tuple(data)\n",
        "\n",
        "        return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ipykernel_launcher:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "# default `log_dir` is \"runs\" - we'll be more specific here\n",
        "writer = SummaryWriter('runs/FCN_resnet101_GPU_text_pixel_masking/'+experiment_name) \n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(train_dataloader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# create grid of images\n",
        "img_grid = torchvision.utils.make_grid(images)\n",
        "\n",
        "# write to tensorboard\n",
        "writer.add_image('FCN_resnet101_GPU_text_pixel_masking_images', img_grid)\n",
        "\n",
        "model_wrapper = ModelWrapper(model)\n",
        "writer.add_graph(model_wrapper, torch.tensor(images).to('cuda'))\n",
        "writer.close()\n",
        "\n",
        "\n",
        "def plot_classes_preds(images, preds, labels):\n",
        "    '''\n",
        "    Generates matplotlib Figure using a trained network, along with images\n",
        "    and labels from a batch, that shows the network's top prediction along\n",
        "    with its probability, alongside the actual label, coloring this\n",
        "    information based on whether the prediction was correct or not.\n",
        "    Uses the \"images_to_probs\" function.\n",
        "    '''\n",
        "\n",
        "    fig = plt.figure(figsize=(8, 4))\n",
        "\n",
        "    fig.add_subplot(1, 3, 1, xticks=[], yticks=[])\n",
        "    input_image = images.squeeze()\n",
        "    # print('input_image', input_image.shape)\n",
        "    plt.imshow(input_image)\n",
        "\n",
        "    fig.add_subplot(1, 3, 2, xticks=[], yticks=[])\n",
        "    plt.imshow(preds.reshape((img_height,img_width)).detach().cpu().numpy(), cmap='gray')\n",
        "\n",
        "    fig.add_subplot(1, 3, 3, xticks=[], yticks=[])\n",
        "    label = labels.reshape((img_width, img_height)).long().detach().cpu()\n",
        "    plt.imshow(label, cmap='gray')\n",
        "\n",
        "\n",
        "    return fig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "f449bec8",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\maxan\\Documents\\Programming\\MemeMachine\\MemeMachine\\TextPixelMasking\\GPUtextPixelMasking\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "FCN(\n",
              "  (backbone): IntermediateLayerGetter(\n",
              "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (layer1): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer2): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer3): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (4): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (5): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer4): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (classifier): FCNHead(\n",
              "    (0): Conv2d(2048, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): Dropout(p=0.1, inplace=False)\n",
              "    (4): Conv2d(512, 2, kernel_size=(1, 1), stride=(1, 1))\n",
              "  )\n",
              "  (aux_classifier): FCNHead(\n",
              "    (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): Dropout(p=0.1, inplace=False)\n",
              "    (4): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "\n",
        "# criterion = nn.CrossEntropyLoss(size_average=False, reduction='sum')\n",
        "criterion = nn.SoftMarginLoss(size_average=False, reduction='sum')\n",
        "# optimizer = optim.SGD(model.parameters(), lr=10**-10, momentum=0.99) #TODO change learning rate to a lower number\n",
        "if torch.cuda.is_available():\n",
        "    model.to('cuda')\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "model.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "c7e2c12f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "999\n",
            "cost tensor(5714.5083, device='cuda:0', grad_fn=<SoftMarginLossBackward0>)\n",
            "1999\n",
            "cost tensor(5366.3960, device='cuda:0', grad_fn=<SoftMarginLossBackward0>)\n",
            "2999\n",
            "cost tensor(5573.7778, device='cuda:0', grad_fn=<SoftMarginLossBackward0>)\n",
            "3999\n",
            "cost tensor(5696.4614, device='cuda:0', grad_fn=<SoftMarginLossBackward0>)\n",
            "4999\n",
            "cost tensor(6281.3472, device='cuda:0', grad_fn=<SoftMarginLossBackward0>)\n",
            "5999\n",
            "cost tensor(5345.5947, device='cuda:0', grad_fn=<SoftMarginLossBackward0>)\n",
            "6999\n",
            "cost tensor(5582.4937, device='cuda:0', grad_fn=<SoftMarginLossBackward0>)\n",
            "7999\n",
            "cost tensor(5582.2324, device='cuda:0', grad_fn=<SoftMarginLossBackward0>)\n",
            "8999\n",
            "cost tensor(6044.6265, device='cuda:0', grad_fn=<SoftMarginLossBackward0>)\n",
            "9999\n",
            "cost tensor(5738.9688, device='cuda:0', grad_fn=<SoftMarginLossBackward0>)\n",
            "10999\n",
            "cost tensor(5421.1162, device='cuda:0', grad_fn=<SoftMarginLossBackward0>)\n",
            "11999\n",
            "cost tensor(6048.8076, device='cuda:0', grad_fn=<SoftMarginLossBackward0>)\n",
            "12999\n",
            "cost tensor(5563.8057, device='cuda:0', grad_fn=<SoftMarginLossBackward0>)\n",
            "13999\n",
            "cost tensor(5856.0361, device='cuda:0', grad_fn=<SoftMarginLossBackward0>)\n",
            "14999\n",
            "cost tensor(5372.7026, device='cuda:0', grad_fn=<SoftMarginLossBackward0>)\n",
            "15999\n",
            "cost tensor(5726.7764, device='cuda:0', grad_fn=<SoftMarginLossBackward0>)\n",
            "16999\n",
            "cost tensor(5394.3682, device='cuda:0', grad_fn=<SoftMarginLossBackward0>)\n",
            "17999\n",
            "cost tensor(5652.7686, device='cuda:0', grad_fn=<SoftMarginLossBackward0>)\n",
            "18999\n",
            "cost tensor(5655.0620, device='cuda:0', grad_fn=<SoftMarginLossBackward0>)\n",
            "19999\n",
            "cost tensor(5483.3672, device='cuda:0', grad_fn=<SoftMarginLossBackward0>)\n",
            "20999\n",
            "cost tensor(6239.4805, device='cuda:0', grad_fn=<SoftMarginLossBackward0>)\n",
            "21999\n",
            "cost tensor(5417.7651, device='cuda:0', grad_fn=<SoftMarginLossBackward0>)\n",
            "22999\n",
            "cost tensor(5194.2109, device='cuda:0', grad_fn=<SoftMarginLossBackward0>)\n",
            "23999\n",
            "cost tensor(5667.2227, device='cuda:0', grad_fn=<SoftMarginLossBackward0>)\n",
            "24999\n",
            "cost tensor(5387.0928, device='cuda:0', grad_fn=<SoftMarginLossBackward0>)\n",
            "25999\n",
            "cost tensor(5618.6543, device='cuda:0', grad_fn=<SoftMarginLossBackward0>)\n",
            "26999\n",
            "cost tensor(5595.0864, device='cuda:0', grad_fn=<SoftMarginLossBackward0>)\n",
            "27999\n",
            "cost tensor(5468.7573, device='cuda:0', grad_fn=<SoftMarginLossBackward0>)\n",
            "28999\n",
            "cost tensor(5293.9775, device='cuda:0', grad_fn=<SoftMarginLossBackward0>)\n",
            "29999\n",
            "cost tensor(5387.3286, device='cuda:0', grad_fn=<SoftMarginLossBackward0>)\n",
            "30999\n",
            "cost tensor(5414.2861, device='cuda:0', grad_fn=<SoftMarginLossBackward0>)\n",
            "31999\n",
            "cost tensor(5556.6904, device='cuda:0', grad_fn=<SoftMarginLossBackward0>)\n",
            "32999\n",
            "cost tensor(5742.6313, device='cuda:0', grad_fn=<SoftMarginLossBackward0>)\n",
            "33999\n",
            "cost tensor(5562.9082, device='cuda:0', grad_fn=<SoftMarginLossBackward0>)\n",
            "34999\n",
            "cost tensor(5459.9375, device='cuda:0', grad_fn=<SoftMarginLossBackward0>)\n",
            "35999\n",
            "cost tensor(5618.7490, device='cuda:0', grad_fn=<SoftMarginLossBackward0>)\n",
            "999\n",
            "cost tensor(6191.4805, device='cuda:0', grad_fn=<SoftMarginLossBackward0>)\n",
            "1999\n",
            "cost tensor(5380.3911, device='cuda:0', grad_fn=<SoftMarginLossBackward0>)\n",
            "2999\n",
            "cost tensor(6305.4805, device='cuda:0', grad_fn=<SoftMarginLossBackward0>)\n",
            "3999\n",
            "cost tensor(5468.6377, device='cuda:0', grad_fn=<SoftMarginLossBackward0>)\n",
            "4999\n",
            "cost tensor(5586.2148, device='cuda:0', grad_fn=<SoftMarginLossBackward0>)\n",
            "5999\n",
            "cost tensor(6483.4805, device='cuda:0', grad_fn=<SoftMarginLossBackward0>)\n",
            "6999\n",
            "cost tensor(5413.6504, device='cuda:0', grad_fn=<SoftMarginLossBackward0>)\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-9-37fa983bcc3f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\maxan\\Documents\\Programming\\MemeMachine\\MemeMachine\\TextPixelMasking\\GPUtextPixelMasking\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 307\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\maxan\\Documents\\Programming\\MemeMachine\\MemeMachine\\TextPixelMasking\\GPUtextPixelMasking\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 156\u001b[1;33m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "model.train()\n",
        "\n",
        "# Train the model\n",
        "last_epoch_loss = 0.0\n",
        "mini_epoch_loss = 0.0\n",
        "epoch_loss = 0.0\n",
        "for epoch in range(100):  # loop over the dataset multiple times  \n",
        "\n",
        "    for i, data in enumerate(train_dataloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "        # print(inputs.shape)\n",
        "\n",
        "        inputs = inputs.squeeze()\n",
        "        inputs = np.moveaxis(inputs.detach().cpu().numpy(), 0, -1)\n",
        "        # print(inputs.shape)\n",
        "        preprocessed_inputs = cv.cvtColor(inputs, cv.COLOR_BGR2RGB)\n",
        "        preprocessed_inputs = Image.fromarray(np.uint8(preprocessed_inputs))\n",
        "        preprocessed_inputs = preprocessed_inputs.convert(\"RGB\")\n",
        "        preprocessed_inputs = preprocess(preprocessed_inputs)\n",
        "        preprocessed_inputs = preprocessed_inputs.unsqueeze(0)\n",
        "\n",
        "        # move the input and model to GPU for speed if available\n",
        "        if torch.cuda.is_available():\n",
        "            preprocessed_inputs = preprocessed_inputs.to('cuda')\n",
        "            labels = labels.to('cuda')\n",
        "            model.to('cuda')\n",
        "            \n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        output = model(preprocessed_inputs)['out'][0]\n",
        "        # print(output.shape)\n",
        "        output = nn.Softmax(dim=0)(output)\n",
        "        output = output[1] - output[0]\n",
        "        # print(output.shape)\n",
        "        # print(output)\n",
        "        # print(output.shape)\n",
        "        output = torch.unsqueeze(output, 0)\n",
        "        output = torch.unsqueeze(output, 0)\n",
        "        # output = torch.sigmoid(output) FIXME why use this?\n",
        "        # print(output.shape)\n",
        "\n",
        "        # output_predictions = output.argmax(0)\n",
        "        labels = torch.reshape(labels, (1, img_height,img_width))\n",
        "        # labels = labels*256\n",
        "        labels[labels<=0] = -1\n",
        "        labels[labels>0] = 1\n",
        "        labels = labels.long()\n",
        "        # print(\"output\", output)\n",
        "\n",
        "\n",
        "        loss = criterion(output, labels)\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        epoch_loss += loss.item()\n",
        "        mini_epoch_loss += loss.item()\n",
        "        if i % 1000 == 999:    # print every 1000 mini-batches\n",
        "        # if i % 100 == 1:    # print every 100 mini-batches\n",
        "        # if i % 2 == 1:    # print every 2 mini-batches\n",
        "            print(i)\n",
        "            print(\"cost\", loss)\n",
        "            writer.add_scalar('total mini-epoch loss',\n",
        "                mini_epoch_loss,\n",
        "                epoch * len(train_dataloader) + i)\n",
        "                \n",
        "            writer.add_scalar('average mini-epoch loss',\n",
        "                mini_epoch_loss / 1000,\n",
        "                epoch * len(train_dataloader) + i)\n",
        "\n",
        "            mini_epoch_loss = 0.0\n",
        "            writer.add_scalar('most recent cost',\n",
        "                            loss.item(),\n",
        "                            epoch * len(train_dataloader) + i)\n",
        "\n",
        "            # ...log a Matplotlib Figure showing the model's predictions on a\n",
        "            # random mini-batch\n",
        "            writer.add_figure('input vs output vs label',\n",
        "                            plot_classes_preds(inputs, output, labels),\n",
        "                            global_step=epoch * len(train_dataloader) + i) \n",
        "  \n",
        "    writer.add_scalar('total epoch loss',\n",
        "                    epoch_loss,\n",
        "                    epoch * len(train_dataloader) + i)\n",
        "    writer.add_scalar('average epoch loss',\n",
        "                    epoch_loss / \n",
        "                    (epoch * len(train_dataloader) + i),\n",
        "                    epoch * len(train_dataloader) + i)\n",
        "\n",
        "    if last_epoch_loss == 0 or last_epoch_loss > epoch_loss:\n",
        "        torch.save({\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'loss': loss,\n",
        "                }, 'model_saves/'+experiment_name+\".pytorch_model\")\n",
        " \n",
        "print('Finished Training')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e79758fc",
      "metadata": {},
      "outputs": [],
      "source": [
        "def test(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8caa42c6",
      "metadata": {},
      "source": [
        "Show a test of the newly trained (fine tuned) model below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.eval()\n",
        "\n",
        "# Display image and label.\n",
        "test_features, test_labels = next(iter(test_dataloader))\n",
        "print(f\"Feature batch shape: {test_features.size()}\")\n",
        "print(f\"Labels batch shape: {test_labels.size()}\")\n",
        "input_image = test_features[0].squeeze()\n",
        "input_image = np.moveaxis(input_image.numpy(), 0, -1)\n",
        "label = test_labels[0].reshape((img_width, img_height))\n",
        "\n",
        "plt.imshow(input_image, cmap=\"gray\")\n",
        "plt.show()\n",
        "plt.imshow(label, cmap=\"gray\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2f76b07",
      "metadata": {},
      "outputs": [],
      "source": [
        "# input_image = Image.open(filename)\n",
        "input_image2 = cv.cvtColor(input_image, cv.COLOR_BGR2RGB)\n",
        "input_image2 = Image.fromarray(np.uint8(input_image2))\n",
        "input_image2 = input_image2.convert(\"RGB\")\n",
        "\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "input_tensor = preprocess(input_image)\n",
        "input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
        "\n",
        "# move the input and model to GPU for speed if available\n",
        "if torch.cuda.is_available():\n",
        "    input_batch = input_batch.to('cuda')\n",
        "    model.to('cuda')\n",
        "\n",
        "with torch.no_grad():\n",
        "    output = model(input_batch)['out'][0] #zero refers to the batch number?\n",
        "output_predictions = output.argmax(0)\n",
        "print(output_predictions)\n",
        "print(output_predictions.shape)\n",
        "print(output)\n",
        "print(output.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d9d37c0",
      "metadata": {},
      "outputs": [],
      "source": [
        "test(test_dataloader, model, criterion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee44acb2",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "pytorch_vision_fcn_resnet101.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
